{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import plotnine as p9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/external/train_logs.csv\")\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .sort_values([\"id\", \"event_id\"], ascending=[True, True])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = X_train.loc[(\n",
    "    (X_train['activity'] == 'Input')\n",
    "    & (~ X_train['text_change'].isin(['q', ' ']))\n",
    "    ), 'text_change'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Move From' activity recorded with low-level cursor loc details\n",
    "# extract bigger-picture 'Move From'\n",
    "# QUESTION: what's the difference between Move From, and a cut+paste?\n",
    "X_train['activity_detailed'] = X_train['activity']\n",
    "X_train.loc[X_train['activity'].str.contains('Move From'), 'activity'] = 'Move'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no explicit record for a pause. pauses are omitted.\n",
    "PAUSE_THRESHOLD_MS = 1000\n",
    "\n",
    "X_train['up_time_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['up_time']\n",
    "    .shift(1)\n",
    "    )\n",
    "# latency does not mean a meaningful pause\n",
    "X_train['latency_time'] = (\n",
    "    X_train['down_time'] - X_train['up_time_lag1']\n",
    "    )\n",
    "\n",
    "X_train['preceding_pause_time'] = X_train['latency_time']\n",
    "# first record lacks preceding_pause_time: that's time before first key press\n",
    "X_train.loc[X_train['event_id'] == 1, 'preceding_pause_time'] = X_train['down_time']\n",
    "# expect some negative pause times -- interpret as, no real pause\n",
    "has_no_real_pause = X_train['preceding_pause_time'] <= PAUSE_THRESHOLD_MS\n",
    "X_train.loc[has_no_real_pause, 'preceding_pause_time'] = None\n",
    "# not obvious how to tag \"initial planning pause\" \n",
    "# tried \"first 5 minutes\", but when that pause is 10 minutes, that fails.\n",
    "# first XX minutes is fragile\n",
    "# first XX events may help -- what's your extent of pause before *action*?\n",
    "N_ACTIVITIES_UNTIL_START_WINDOW_CLOSES = 100\n",
    "X_train['preceding_pause_time_start_window'] = X_train['preceding_pause_time']\n",
    "X_train.loc[X_train['event_id'] <= N_ACTIVITIES_UNTIL_START_WINDOW_CLOSES, 'preceding_pause_time_start_window'] = None\n",
    "\n",
    "X_train['total_pause_time'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['preceding_pause_time']\n",
    "    .transform('sum')\n",
    "    )\n",
    "X_train['rolling_pause_time'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['preceding_pause_time']\n",
    "    .cumsum()\n",
    "    )\n",
    "X_train['rolling_pause_time_fraction'] = (\n",
    "    X_train['rolling_pause_time'] / X_train['total_pause_time']\n",
    "    )\n",
    "\n",
    "# summarize pause distr\n",
    "MS_IN_PAUSE_BUCKET_MAX = 200e3\n",
    "PAUSE_BUCKET_STEP_MS = 500\n",
    "\n",
    "X_train['preceding_pause_time_bucket'] = pd.cut(\n",
    "    X_train['preceding_pause_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        MS_IN_PAUSE_BUCKET_MAX,\n",
    "        PAUSE_BUCKET_STEP_MS\n",
    "        )\n",
    "    )\n",
    "\n",
    "# X_train['preceding_pause_time_bucket'].value_counts()\n",
    "\n",
    "# WARNING: this representation of pause distribution is dense & large\n",
    "# a few parameters from distribution model far more succinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34969/101131515.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# if pause exceeds threshold duration, a \"burst\" has ended\n",
    "MS_PER_S = 1000\n",
    "SECONDS_PER_BURST = 2\n",
    "\n",
    "X_train['is_new_burst_start'] = (\n",
    "    X_train['preceding_pause_time'] > MS_PER_S * SECONDS_PER_BURST\n",
    "    ).astype(int)\n",
    "X_train['is_new_burst_start'][0] = 1\n",
    "X_train['burst_id'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['is_new_burst_start']\n",
    "    .cumsum()\n",
    "    )\n",
    "X_train['burst_time_start'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['down_time']\n",
    "    .transform('min')\n",
    "    )\n",
    "X_train['burst_time_end'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['up_time']\n",
    "    .transform('max')\n",
    "    )\n",
    "X_train['burst_time_duration'] = (\n",
    "    X_train['burst_time_end'] - X_train['burst_time_start']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count offers a productivity measure\n",
    "X_train['word_count_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['word_count']\n",
    "    .shift(1)\n",
    "    )\n",
    "\n",
    "X_train['word_count_delta_event'] = (\n",
    "    X_train['word_count'] - X_train['word_count_lag1']\n",
    "    )\n",
    "\n",
    "X_train['word_count_delta_burst'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['word_count_delta_event']\n",
    "    .transform('sum')\n",
    "    )\n",
    "# de-duplicate to one value per burst -- easier for downstream aggregation\n",
    "X_train['word_count_delta_burst_thin'] = X_train['word_count_delta_burst']\n",
    "X_train.loc[X_train['is_new_burst_start'] == 0, 'word_count_delta_burst_thin'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-way cursor movement might be most productive\n",
    "# jumping around is choppy\n",
    "X_train['cursor_position_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position']\n",
    "    .shift(1)\n",
    "    )\n",
    "\n",
    "X_train['has_cursor_position_moved_right'] = (\n",
    "    X_train['cursor_position'] > X_train['cursor_position_lag1']\n",
    "    ).astype(int)\n",
    "\n",
    "# if cursor position increases due to copy+paste (perhaps of essay prompt),\n",
    "# that doesn't reflect grade-driving output\n",
    "X_train['cursor_position_input'] = np.where(\n",
    "    X_train['activity'] == \"Input\", \n",
    "    X_train[\"cursor_position\"], \n",
    "    np.nan\n",
    "    )\n",
    "X_train['cursor_position_cummax'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position_input']\n",
    "    .cummax()\n",
    "    )\n",
    "# for some reason, unable to chain below statements with above\n",
    "X_train['cursor_position_cummax'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position_cummax']\n",
    "    .ffill()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "X_train['cursor_position_vs_max'] = (\n",
    "    X_train['cursor_position'] - X_train['cursor_position_cummax']\n",
    "    )\n",
    "\n",
    "X_train['cursor_position_last_space'] = np.where(\n",
    "    (X_train['activity'] == \"Input\") & (X_train[\"text_change\"] == ' '),\n",
    "    X_train['cursor_position'],\n",
    "    np.nan\n",
    ") \n",
    "X_train['cursor_position_last_space'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position_last_space']\n",
    "    .ffill()\n",
    "    # likely not beginning essay with a space\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "X_train = X_train.drop(columns='cursor_position_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word length offers a content quality measure.\n",
    "# hard to track entire words sequence in rolling fashion.\n",
    "    # every word's length, in a list of one element per word?  \n",
    "# more tractable to track very latest string\n",
    "\n",
    "is_edit_to_latest_string = (\n",
    "    X_train['cursor_position'] > X_train['cursor_position_last_space']\n",
    ")\n",
    "\n",
    "X_train['is_latest_space'] = (\n",
    "    (X_train['cursor_position_vs_max'] == 0)\n",
    "    & (X_train['activity'] == \"Input\")\n",
    "    & (X_train[\"text_change\"] == ' ')\n",
    "    )\n",
    "\n",
    "X_train['is_latest_string_end'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['is_latest_space']\n",
    "    .shift(-1)\n",
    "    # last process records\n",
    "    .fillna(True)\n",
    "    )\n",
    "\n",
    "X_train['n_alphanum_char_added_to_latest_string'] = 0\n",
    "is_alphanumeric_addition = (\n",
    "    (X_train['activity'] == \"Input\")\n",
    "    & (X_train[\"text_change\"] == 'q')\n",
    "    )\n",
    "X_train.loc[\n",
    "    (is_alphanumeric_addition & is_edit_to_latest_string), \n",
    "    'n_alphanum_char_added_to_latest_string'\n",
    "    ] = 1\n",
    "is_alphanumeric_subtraction = (\n",
    "    (X_train['activity'] == \"Remove/Cut\")\n",
    "    & (X_train['up_event'] == 'Backspace')\n",
    "    & (X_train[\"text_change\"] == 'q')\n",
    "    )\n",
    "X_train.loc[\n",
    "    (is_alphanumeric_subtraction & is_edit_to_latest_string), \n",
    "    'n_alphanum_char_added_to_latest_string'\n",
    "    ] = -1\n",
    "\n",
    "# example: 2nd string, 2 characters in.\n",
    "# considering cumsum for each character in 2nd string, \n",
    "# subtract those characters from 1st\n",
    "X_train['rolling_length_strings'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['n_alphanum_char_added_to_latest_string']\n",
    "    .cumsum() \n",
    "    ) \n",
    "\n",
    "X_train['rolling_length_completed_strings'] = None\n",
    "X_train.loc[\n",
    "    X_train['is_latest_space'], 'rolling_length_completed_strings'\n",
    "     ] = X_train['rolling_length_strings']\n",
    "X_train['rolling_length_completed_strings'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['rolling_length_completed_strings']\n",
    "    .ffill()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "X_train['rolling_length_latest_string'] = (\n",
    "    X_train['rolling_length_strings'] \n",
    "    - X_train['rolling_length_completed_strings']\n",
    ")\n",
    "\n",
    "X_train['length_latest_string'] = None\n",
    "X_train.loc[\n",
    "    X_train['is_latest_string_end'], 'length_latest_string'\n",
    "    ] = X_train['rolling_length_latest_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if thoughts aren't separated by punctuation, writing won't score well\n",
    "X_train['is_thought_delimiting_punctuation'] = (\n",
    "    (X_train['text_change'] == \".\")\n",
    "    | (X_train['text_change'] == \". \")\n",
    "    | (X_train['text_change'] == \",\")\n",
    "    | (X_train['text_change'] == \"-\")\n",
    "    | (X_train['text_change'] == \"!\")\n",
    "    | (X_train['text_change'] == \";\")\n",
    "    | (X_train['text_change'] == \"?\")\n",
    "    | (X_train['text_change'] == \":\")\n",
    "    ).astype(int)\n",
    "\n",
    "X_train['is_special_punctuation'] = (\n",
    "    (X_train['text_change'] == \"=\")\n",
    "    | (X_train['text_change'] == \"/\")\n",
    "    | (X_train['text_change'] == \"\\\\\")\n",
    "    | (X_train['text_change'] == \"(\")\n",
    "    | (X_train['text_change'] == \")\")\n",
    "    | (X_train['text_change'] == \"\\n\")\n",
    "    | (X_train['text_change'] == \"[\")\n",
    "    | (X_train['text_change'] == \"]\")\n",
    "    | (X_train['text_change'] == \">\")\n",
    "    | (X_train['text_change'] == \"<\")\n",
    "    | (X_train['text_change'] == \"$\")\n",
    "    | (X_train['text_change'] == \"*\")\n",
    "    | (X_train['text_change'] == \"&\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows allow for time-sequence features\n",
    "# expect that some essays extend beyond 30 min described in 'Data Collection'\n",
    "# downstream, **do not tabulate over a writer's unused time windows**!!\n",
    "TOTAL_MIN_MAX_EXPECTED = 30\n",
    "TOTAL_MIN_PLUS_BUFFER = 150 # id 21bbc3f6 case extended to 140 min ... odd\n",
    "SECONDS_PER_MIN = 60\n",
    "SECONDS_PER_WINDOW = 30\n",
    "\n",
    "X_train['window_30s'] = pd.cut(\n",
    "    X_train['down_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        TOTAL_MIN_PLUS_BUFFER * SECONDS_PER_MIN * MS_PER_S, \n",
    "        SECONDS_PER_WINDOW * MS_PER_S\n",
    "        )\n",
    "    )\n",
    "\n",
    "X_train['is_time_beyond_expected_max'] = (\n",
    "    X_train['up_time'] > TOTAL_MIN_MAX_EXPECTED * SECONDS_PER_MIN * MS_PER_S\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    }
   ],
   "source": [
    "ACTIVITY_CATEGORIES = ['Nonproduction', 'Input', 'Remove/Cut', 'Replace', 'Paste', 'Move']\n",
    "\n",
    "pipeline_activity_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ACTIVITY_CATEGORIES], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"activity\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_activity_onehot.fit(X_train)\n",
    "original_categorical = X_train['activity']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_activity_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_activity_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['burst_events_' + activity] = (\n",
    "        X_train\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['activity_' + activity]\n",
    "        .transform('sum')\n",
    "        ).astype(float)\n",
    "    \n",
    "X_train['burst_type'] = (\n",
    "    X_train\n",
    "    [['burst_events_' + activity for activity in ACTIVITY_CATEGORIES]]\n",
    "    .idxmax(axis=1)\n",
    "    )\n",
    "X_train['burst_type'] = (\n",
    "    X_train['burst_type']\n",
    "    .str\n",
    "    .replace(\"burst_events_\", \"\", regex=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    }
   ],
   "source": [
    "pipeline_burst_type_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ACTIVITY_CATEGORIES], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"burst_type\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_burst_type_onehot.fit(X_train)\n",
    "original_categorical = X_train['burst_type']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_burst_type_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_burst_type_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)\n",
    "\n",
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['is_new_burst_start_' + activity] = (\n",
    "        X_train['is_new_burst_start'] * \n",
    "        X_train['burst_type_' + activity]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[\n",
    "    \"id\",\n",
    "    \"event_id\",\n",
    "    \"is_time_beyond_expected_max\",\n",
    "    \"window_30s\",\n",
    "    \"burst_id\",\n",
    "    \"burst_type\",\n",
    "    \"burst_type_Nonproduction\",\n",
    "    \"burst_type_Input\",\n",
    "    \"burst_type_Remove/Cut\",\n",
    "    \"burst_type_Replace\",\n",
    "    \"burst_type_Paste\",\n",
    "    \"burst_type_Move\",\n",
    "    \"is_new_burst_start\",\n",
    "    \"is_new_burst_start_Nonproduction\",\n",
    "    \"is_new_burst_start_Input\",\n",
    "    \"is_new_burst_start_Remove/Cut\",\n",
    "    \"is_new_burst_start_Replace\",\n",
    "    \"is_new_burst_start_Paste\",\n",
    "    \"is_new_burst_start_Move\",\n",
    "    \"burst_time_start\",\n",
    "    \"burst_time_end\",\n",
    "    \"burst_time_duration\",\n",
    "    \"burst_events_Nonproduction\",\n",
    "    \"burst_events_Input\",\n",
    "    \"burst_events_Remove/Cut\",\n",
    "    \"burst_events_Replace\",\n",
    "    \"burst_events_Paste\",\n",
    "    \"burst_events_Move\",\n",
    "    \"word_count_delta_burst\",\n",
    "    \"word_count_delta_burst_thin\",\n",
    "\n",
    "    \"down_time\",\n",
    "    \"up_time\",\t\n",
    "    \"action_time\",\t\n",
    "    \"activity_detailed\",\n",
    "    \"activity\",\t\n",
    "    \"activity_Nonproduction\",\n",
    "    \"activity_Input\",\n",
    "    \"activity_Remove/Cut\",\n",
    "    \"activity_Replace\",\n",
    "    \"activity_Paste\",\n",
    "    \"activity_Move\",\n",
    "    \"down_event\",\t\n",
    "    \"up_event\",\t\n",
    "    \"text_change\",\n",
    "    \"is_thought_delimiting_punctuation\",\n",
    "    \"cursor_position\",\t\n",
    "    \"word_count\",\n",
    "\n",
    "    \"cursor_position_vs_max\",\n",
    "    \"cursor_position_cummax\",\n",
    "    \"has_cursor_position_moved_right\",\n",
    "    \"cursor_position_last_space\",\n",
    "\n",
    "    \"is_latest_space\",\n",
    "    \"is_latest_string_end\",\n",
    "    \"n_alphanum_char_added_to_latest_string\",\n",
    "    \"rolling_length_latest_string\",\n",
    "    \"length_latest_string\",\n",
    "\n",
    "    \"word_count_lag1\",\n",
    "    \"word_count_delta_event\",\n",
    "\n",
    "    \"up_time_lag1\",\n",
    "    \"latency_time\",\n",
    "    \"preceding_pause_time\",\n",
    "    \"preceding_pause_time_start_window\",\n",
    "    \"preceding_pause_time_bucket\",\n",
    "    \"rolling_pause_time\",\n",
    "    \"rolling_pause_time_fraction\",\n",
    "    \"total_pause_time\"\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"./data/processed/train_logs_enriched.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train\n",
    "    .query(\"id == '001519c8'\")\n",
    "    .to_csv(\"./data/X_train_enriched_case.csv\", index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_vars_sum = (\n",
    "    ['activity_' + x for x in ACTIVITY_CATEGORIES] \n",
    "    + ['is_new_burst_start'] \n",
    "    + ['is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    + [\"is_thought_delimiting_punctuation\"]\n",
    "    )\n",
    "\n",
    "events_sum_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    [event_vars_sum]\n",
    "    .agg(sum)\n",
    "    )\n",
    "\n",
    "events_sum_over_time['delete_insert_ratio'] = (\n",
    "    events_sum_over_time['activity_Remove/Cut'] / \n",
    "    events_sum_over_time['activity_Input'] \n",
    "    )\n",
    "\n",
    "conti_vars_sum = (\n",
    "    ['word_count_delta_event']\n",
    "    + [\"preceding_pause_time\"]\n",
    "    )\n",
    "\n",
    "conti_sum_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    [conti_vars_sum]\n",
    "    .agg(sum)\n",
    "    )\n",
    "\n",
    "sums_over_time = pd.merge(\n",
    "    events_sum_over_time,\n",
    "    conti_sum_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrals_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        latency_time_p50 = ('latency_time', np.median),\n",
    "        pause_time_p50 = ('preceding_pause_time', np.median),\n",
    "        has_cursor_position_moved_right_mean = ('has_cursor_position_moved_right', 'mean'),\n",
    "        word_count_delta_burst_mean = ('word_count_delta_burst_thin', 'mean'),\n",
    "        word_count_delta_burst_p50 = ('word_count_delta_burst_thin', np.median),\n",
    "        cursor_position_vs_max_avg = ('cursor_position_vs_max', 'mean'),\n",
    "        length_latest_string_mean = ('length_latest_string', 'mean'),\n",
    "        length_latest_string_stddev = ('length_latest_string', np.std)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        pause_time_max=('preceding_pause_time', 'max'),\n",
    "        initial_pause_time_max=('preceding_pause_time_start_window', 'max'),\n",
    "        # approximation to, next longest pause after first long planning pause\n",
    "        pause_time_p99=('preceding_pause_time', lambda x: x.quantile(0.99)),\n",
    "        word_count_delta_burst_max=('word_count_delta_burst_thin', 'max'),\n",
    "        total_time=('up_time', 'max'),\n",
    "        length_latest_string_max=('length_latest_string', 'max'),\n",
    "        latency_time_min=('latency_time', 'min'),\n",
    "        is_time_beyond_expected_max=('is_time_beyond_expected_max', 'max')\n",
    "        )\n",
    "    )\n",
    "\n",
    "extremes_over_time['is_initial_pause_max_pause'] = (\n",
    "    extremes_over_time['pause_time_max'] == \n",
    "    extremes_over_time['initial_pause_time_max']\n",
    "    ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm\n",
    "\n",
    "pause_distr_summary_subjects = []\n",
    "\n",
    "for X_train_subject in [x for _, x in X_train.groupby('id')]:\n",
    "\n",
    "    shape, location, scale = lognorm.fit(X_train_subject['preceding_pause_time'].dropna())\n",
    "\n",
    "    pause_distr_summary = pd.DataFrame({\n",
    "        'pauses_lognorm_shape': [shape], \n",
    "        'pauses_lognorm_location': [location],\n",
    "        'pauses_lognorm_scale': [scale]\n",
    "        })\n",
    "    pause_distr_summary.index = [X_train_subject['id'].iloc[0]]\n",
    "    \n",
    "    pause_distr_summary_subjects.append(pause_distr_summary)\n",
    "\n",
    "distr_params_over_time = pd.concat(pause_distr_summary_subjects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_over_time = pd.merge(\n",
    "    sums_over_time, \n",
    "    centrals_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "aggregates_over_time = pd.merge(\n",
    "    aggregates_over_time, \n",
    "    extremes_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "aggregates_over_time = pd.merge(\n",
    "    aggregates_over_time, \n",
    "    distr_params_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in event_vars_sum:\n",
    "\n",
    "    aggregates_over_time[var + '_per_s'] = (\n",
    "        1000 * (aggregates_over_time[var] / aggregates_over_time['total_time'])\n",
    "        )\n",
    "\n",
    "aggregates_over_time = (\n",
    "    aggregates_over_time\n",
    "    .assign(\n",
    "        keystroke_speed = lambda x: (x.activity_Input + x['activity_Remove/Cut']) / x.total_time,\n",
    "        words_per_thought_delimiting_punctuation = lambda x: x.word_count_delta_event / x.is_thought_delimiting_punctuation,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_Nonproduction</th>\n",
       "      <th>activity_Input</th>\n",
       "      <th>activity_Remove/Cut</th>\n",
       "      <th>activity_Replace</th>\n",
       "      <th>activity_Paste</th>\n",
       "      <th>activity_Move</th>\n",
       "      <th>is_new_burst_start</th>\n",
       "      <th>is_new_burst_start_Nonproduction</th>\n",
       "      <th>is_new_burst_start_Input</th>\n",
       "      <th>is_new_burst_start_Remove/Cut</th>\n",
       "      <th>...</th>\n",
       "      <th>is_new_burst_start_per_s</th>\n",
       "      <th>is_new_burst_start_Nonproduction_per_s</th>\n",
       "      <th>is_new_burst_start_Input_per_s</th>\n",
       "      <th>is_new_burst_start_Remove/Cut_per_s</th>\n",
       "      <th>is_new_burst_start_Replace_per_s</th>\n",
       "      <th>is_new_burst_start_Paste_per_s</th>\n",
       "      <th>is_new_burst_start_Move_per_s</th>\n",
       "      <th>is_thought_delimiting_punctuation_per_s</th>\n",
       "      <th>keystroke_speed</th>\n",
       "      <th>words_per_thought_delimiting_punctuation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001519c8</th>\n",
       "      <td>120.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125</td>\n",
       "      <td>23.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069369</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.04939</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023863</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>5.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0022f953</th>\n",
       "      <td>254.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028508</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>6.274510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0042269b</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3515.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>8.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0059420b</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>12.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0075873a</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>8.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053535</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.039098</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035489</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>4.271186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         activity_Nonproduction activity_Input activity_Remove/Cut  \\\n",
       "id                                                                   \n",
       "001519c8                  120.0         2010.0               417.0   \n",
       "0022f953                  254.0         1938.0               260.0   \n",
       "0042269b                  175.0         3515.0               439.0   \n",
       "0059420b                   99.0         1304.0               151.0   \n",
       "0075873a                   72.0         1942.0               517.0   \n",
       "\n",
       "         activity_Replace activity_Paste activity_Move  is_new_burst_start  \\\n",
       "id                                                                           \n",
       "001519c8              7.0            0.0           3.0                 125   \n",
       "0022f953              1.0            1.0           0.0                  81   \n",
       "0042269b              7.0            0.0           0.0                  78   \n",
       "0059420b              1.0            1.0           0.0                  88   \n",
       "0075873a              0.0            0.0           0.0                  89   \n",
       "\n",
       "         is_new_burst_start_Nonproduction is_new_burst_start_Input  \\\n",
       "id                                                                   \n",
       "001519c8                             23.0                     89.0   \n",
       "0022f953                             32.0                     41.0   \n",
       "0042269b                             30.0                     46.0   \n",
       "0059420b                              9.0                     77.0   \n",
       "0075873a                              8.0                     65.0   \n",
       "\n",
       "         is_new_burst_start_Remove/Cut  ... is_new_burst_start_per_s  \\\n",
       "id                                      ...                            \n",
       "001519c8                          13.0  ...                 0.069369   \n",
       "0022f953                           8.0  ...                 0.045277   \n",
       "0042269b                           2.0  ...                 0.044026   \n",
       "0059420b                           2.0  ...                 0.062657   \n",
       "0075873a                          16.0  ...                 0.053535   \n",
       "\n",
       "         is_new_burst_start_Nonproduction_per_s  \\\n",
       "id                                                \n",
       "001519c8                               0.012764   \n",
       "0022f953                               0.017887   \n",
       "0042269b                               0.016933   \n",
       "0059420b                               0.006408   \n",
       "0075873a                               0.004812   \n",
       "\n",
       "         is_new_burst_start_Input_per_s  is_new_burst_start_Remove/Cut_per_s  \\\n",
       "id                                                                             \n",
       "001519c8                        0.04939                             0.007214   \n",
       "0022f953                       0.022918                             0.004472   \n",
       "0042269b                       0.025964                             0.001129   \n",
       "0059420b                       0.054825                             0.001424   \n",
       "0075873a                       0.039098                             0.009624   \n",
       "\n",
       "         is_new_burst_start_Replace_per_s  is_new_burst_start_Paste_per_s  \\\n",
       "id                                                                          \n",
       "001519c8                              0.0                             0.0   \n",
       "0022f953                              0.0                             0.0   \n",
       "0042269b                              0.0                             0.0   \n",
       "0059420b                              0.0                             0.0   \n",
       "0075873a                              0.0                             0.0   \n",
       "\n",
       "          is_new_burst_start_Move_per_s  \\\n",
       "id                                        \n",
       "001519c8                            0.0   \n",
       "0022f953                            0.0   \n",
       "0042269b                            0.0   \n",
       "0059420b                            0.0   \n",
       "0075873a                            0.0   \n",
       "\n",
       "          is_thought_delimiting_punctuation_per_s  keystroke_speed  \\\n",
       "id                                                                   \n",
       "001519c8                                 0.023863         0.001347   \n",
       "0022f953                                 0.028508         0.001229   \n",
       "0042269b                                 0.028222         0.002232   \n",
       "0059420b                                 0.011392         0.001036   \n",
       "0075873a                                 0.035489         0.001479   \n",
       "\n",
       "          words_per_thought_delimiting_punctuation  \n",
       "id                                                  \n",
       "001519c8                                  5.930233  \n",
       "0022f953                                  6.274510  \n",
       "0042269b                                  8.080000  \n",
       "0059420b                                 12.875000  \n",
       "0075873a                                  4.271186  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregates_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_Nonproduction                      0\n",
       "activity_Input                              0\n",
       "activity_Remove/Cut                         0\n",
       "activity_Replace                            0\n",
       "activity_Paste                              0\n",
       "activity_Move                               0\n",
       "is_new_burst_start                          0\n",
       "is_new_burst_start_Nonproduction            0\n",
       "is_new_burst_start_Input                    0\n",
       "is_new_burst_start_Remove/Cut               0\n",
       "is_new_burst_start_Replace                  0\n",
       "is_new_burst_start_Paste                    0\n",
       "is_new_burst_start_Move                     0\n",
       "is_thought_delimiting_punctuation           0\n",
       "delete_insert_ratio                         0\n",
       "word_count_delta_event                      0\n",
       "preceding_pause_time                        0\n",
       "latency_time_p50                            0\n",
       "pause_time_p50                              0\n",
       "has_cursor_position_moved_right_mean        0\n",
       "word_count_delta_burst_mean                 0\n",
       "word_count_delta_burst_p50                  0\n",
       "cursor_position_vs_max_avg                  0\n",
       "length_latest_string_mean                   0\n",
       "length_latest_string_stddev                 0\n",
       "pause_time_max                              0\n",
       "initial_pause_time_max                      0\n",
       "pause_time_p99                              0\n",
       "word_count_delta_burst_max                  0\n",
       "total_time                                  0\n",
       "length_latest_string_max                    0\n",
       "latency_time_min                            0\n",
       "is_time_beyond_expected_max                 0\n",
       "is_initial_pause_max_pause                  0\n",
       "pauses_lognorm_shape                        0\n",
       "pauses_lognorm_location                     0\n",
       "pauses_lognorm_scale                        0\n",
       "activity_Nonproduction_per_s                0\n",
       "activity_Input_per_s                        0\n",
       "activity_Remove/Cut_per_s                   0\n",
       "activity_Replace_per_s                      0\n",
       "activity_Paste_per_s                        0\n",
       "activity_Move_per_s                         0\n",
       "is_new_burst_start_per_s                    0\n",
       "is_new_burst_start_Nonproduction_per_s      0\n",
       "is_new_burst_start_Input_per_s              0\n",
       "is_new_burst_start_Remove/Cut_per_s         0\n",
       "is_new_burst_start_Replace_per_s            0\n",
       "is_new_burst_start_Paste_per_s              0\n",
       "is_new_burst_start_Move_per_s               0\n",
       "is_thought_delimiting_punctuation_per_s     0\n",
       "keystroke_speed                             0\n",
       "words_per_thought_delimiting_punctuation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregates_over_time.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per writer, by default, tabulate _every_ time window ever observed in data.\n",
    "# override: tabulate strictly until writer's final utilized time window.\n",
    "events_by_window = (\n",
    "    X_train\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    [event_vars_sum]\n",
    "    .agg(sum)\n",
    "    .astype(float)\n",
    "    .fillna(0)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "events_by_window['has_activity'] = (\n",
    "    events_by_window[['activity_' + x for x in ACTIVITY_CATEGORIES]].sum(axis=1) \n",
    "    > 0\n",
    ")\n",
    "events_by_window['idx_window_by_id'] = (\n",
    "    events_by_window\n",
    "    .groupby('id')\n",
    "    .cumcount()\n",
    ")\n",
    "events_by_window['idx_has_activity'] = np.where(\n",
    "    events_by_window['has_activity'], \n",
    "    events_by_window['idx_window_by_id'],\n",
    "    np.nan\n",
    "    )\n",
    "events_by_window['idx_activity_max'] = (\n",
    "    events_by_window\n",
    "    .groupby(['id'])\n",
    "    ['idx_has_activity']\n",
    "    .transform('max')\n",
    ")\n",
    "events_by_window = events_by_window.loc[\n",
    "    events_by_window['idx_window_by_id'] <= events_by_window['idx_activity_max']\n",
    "    ]\n",
    "events_by_window = events_by_window.drop(\n",
    "    columns=['has_activity', 'idx_has_activity', 'idx_activity_max']\n",
    "    )\n",
    "\n",
    "events_by_window['delete_insert_ratio'] = (\n",
    "    events_by_window['activity_Remove/Cut'] / \n",
    "    events_by_window['activity_Input'] \n",
    "    ).replace(np.inf, np.nan)\n",
    "\n",
    "\n",
    "# for variability measure more comparable between writers, de-mean by writer. \n",
    "# Ex: higher-throughput writer incurs higher stddev, because values have higher magnitude\n",
    "# join method allows for merge on one index column, of multiple possible\n",
    "events_by_window = events_by_window.join(\n",
    "    aggregates_over_time[[x + '_per_s' for x in event_vars_sum]],\n",
    "    on='id',\n",
    "    how='left'\n",
    "    )\n",
    "for var in event_vars_sum:\n",
    "    events_by_window[var + '_time_norm'] = (\n",
    "        events_by_window[var] / \n",
    "        (events_by_window[var + '_per_s'].replace(0, None) * 30)\n",
    "        ).fillna(1)\n",
    "events_by_window = events_by_window.drop(columns=[x + '_per_s' for x in event_vars_sum])\n",
    "\n",
    "events_over_time_ren = aggregates_over_time[event_vars_sum]\n",
    "events_over_time_ren.columns = [x + \"_total\" for x in events_over_time_ren.columns]\n",
    "events_by_window = events_by_window.join(events_over_time_ren, on='id', how='left')\n",
    "for var in event_vars_sum:\n",
    "    events_by_window[var + '_frac_total'] = (\n",
    "        events_by_window[var] / (events_by_window[var + '_total'].replace(0, None))\n",
    "        ).fillna(1)\n",
    "events_by_window = events_by_window.drop(columns=[x + '_total' for x in event_vars_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conti_by_window = (\n",
    "    X_train\n",
    "    .assign()\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    [conti_vars_sum]\n",
    "    .agg(sum)\n",
    "    .astype(float)\n",
    "    .fillna(0)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "conti_by_window['idx_window_by_id'] = (\n",
    "    conti_by_window\n",
    "    .groupby('id')\n",
    "    .cumcount()\n",
    ")\n",
    "\n",
    "conti_over_time_ren = aggregates_over_time[conti_vars_sum]\n",
    "conti_over_time_ren.columns = [x + \"_total\" for x in conti_over_time_ren.columns]\n",
    "conti_by_window = conti_by_window.join(conti_over_time_ren, on='id', how='left')\n",
    "for var in conti_vars_sum:\n",
    "    conti_by_window[var + '_frac_total'] = (\n",
    "        conti_by_window[var] / conti_by_window[var + '_total']\n",
    "        )\n",
    "conti_by_window = conti_by_window.drop(columns=[x + '_total' for x in conti_vars_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrals_by_window = (\n",
    "    X_train\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    ['cursor_position_vs_max']\n",
    "    .agg('mean')\n",
    "    .astype(float)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "centrals_by_window['idx_window_by_id'] = (\n",
    "    centrals_by_window\n",
    "    .groupby('id')\n",
    "    .cumcount()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_by_window = pd.merge(\n",
    "    events_by_window, \n",
    "    conti_by_window,\n",
    "    # events table reflects, writer's final utilized time window.\n",
    "    # not all possible\n",
    "    how='inner'\n",
    "    )\n",
    "\n",
    "aggregates_by_window = pd.merge(\n",
    "    aggregates_by_window, \n",
    "    centrals_by_window,\n",
    "    how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "entropy_vars = [var for var in aggregates_by_window.columns if 'frac_total' in var]\n",
    "entropy_by_window = (\n",
    "    aggregates_by_window\n",
    "    .groupby(['id'])\n",
    "    [entropy_vars]\n",
    "    .agg(lambda x: entropy(x.value_counts()))\n",
    "    )\n",
    "entropy_by_window.columns = [\n",
    "    x + '_entropy' \n",
    "    for x in entropy_by_window.columns\n",
    "    ]\n",
    "\n",
    "\n",
    "sd_by_window = (\n",
    "    aggregates_by_window\n",
    "    .drop(columns=['window_30s', 'idx_window_by_id'])\n",
    "    .groupby(['id'])\n",
    "    .agg(np.std)\n",
    "    )\n",
    "sd_by_window.columns = [\n",
    "    x + \"_stddev\"\n",
    "    for x in sd_by_window.columns\n",
    "    ]\n",
    "\n",
    "\n",
    "trend_by_window = (\n",
    "    aggregates_by_window\n",
    "    .sort_values(['id', 'idx_window_by_id'])\n",
    "    .drop(columns=['window_30s'])\n",
    "    .groupby(['id'])\n",
    "    .corr()\n",
    "    )\n",
    "# extract correlations strictly with time index\n",
    "trend_by_window = trend_by_window.xs('idx_window_by_id', level=1)\n",
    "\n",
    "vars_drop = (\n",
    "    [x for x in trend_by_window.columns if 'time_norm' in x]\n",
    "    + [x for x in trend_by_window.columns if 'frac_total' in x]\n",
    "    + ['idx_window_by_id']\n",
    "    )\n",
    "trend_by_window = trend_by_window.drop(columns=vars_drop)\n",
    "\n",
    "trend_by_window.columns = [\n",
    "    x + \"_ttrend\"\n",
    "    for x in trend_by_window.columns\n",
    "    ]\n",
    "\n",
    "trend_by_window = trend_by_window.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vari_by_window = pd.merge(\n",
    "    entropy_by_window,\n",
    "    sd_by_window,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )   \n",
    "\n",
    "vari_by_window = pd.merge(\n",
    "    vari_by_window,\n",
    "    trend_by_window,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = pd.merge(\n",
    "    aggregates_over_time,\n",
    "    vari_by_window,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity_Nonproduction': 0.0,\n",
       " 'activity_Input': 0.0,\n",
       " 'activity_Remove/Cut': 0.0,\n",
       " 'activity_Replace': 0.0,\n",
       " 'activity_Paste': 0.0,\n",
       " 'activity_Move': 0.0,\n",
       " 'is_new_burst_start': 0.0,\n",
       " 'is_new_burst_start_Nonproduction': 0.0,\n",
       " 'is_new_burst_start_Input': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut': 0.0,\n",
       " 'is_new_burst_start_Replace': 0.0,\n",
       " 'is_new_burst_start_Paste': 0.0,\n",
       " 'is_new_burst_start_Move': 0.0,\n",
       " 'is_thought_delimiting_punctuation': 0.0,\n",
       " 'delete_insert_ratio': 0.0,\n",
       " 'word_count_delta_event': 0.0,\n",
       " 'preceding_pause_time': 0.0,\n",
       " 'latency_time_p50': 0.0,\n",
       " 'pause_time_p50': 0.0,\n",
       " 'has_cursor_position_moved_right_mean': 0.0,\n",
       " 'word_count_delta_burst_mean': 0.0,\n",
       " 'word_count_delta_burst_p50': 0.0,\n",
       " 'cursor_position_vs_max_avg': 0.0,\n",
       " 'length_latest_string_mean': 0.0,\n",
       " 'length_latest_string_stddev': 0.0,\n",
       " 'pause_time_max': 0.0,\n",
       " 'initial_pause_time_max': 0.0,\n",
       " 'pause_time_p99': 0.0,\n",
       " 'word_count_delta_burst_max': 0.0,\n",
       " 'total_time': 0.0,\n",
       " 'length_latest_string_max': 0.0,\n",
       " 'latency_time_min': 0.0,\n",
       " 'is_time_beyond_expected_max': 0.0,\n",
       " 'is_initial_pause_max_pause': 0.0,\n",
       " 'pauses_lognorm_shape': 0.0,\n",
       " 'pauses_lognorm_location': 0.0,\n",
       " 'pauses_lognorm_scale': 0.0,\n",
       " 'activity_Nonproduction_per_s': 0.0,\n",
       " 'activity_Input_per_s': 0.0,\n",
       " 'activity_Remove/Cut_per_s': 0.0,\n",
       " 'activity_Replace_per_s': 0.0,\n",
       " 'activity_Paste_per_s': 0.0,\n",
       " 'activity_Move_per_s': 0.0,\n",
       " 'is_new_burst_start_per_s': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_per_s': 0.0,\n",
       " 'is_new_burst_start_Input_per_s': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_per_s': 0.0,\n",
       " 'is_new_burst_start_Replace_per_s': 0.0,\n",
       " 'is_new_burst_start_Paste_per_s': 0.0,\n",
       " 'is_new_burst_start_Move_per_s': 0.0,\n",
       " 'is_thought_delimiting_punctuation_per_s': 0.0,\n",
       " 'keystroke_speed': 0.0,\n",
       " 'words_per_thought_delimiting_punctuation': 0.0,\n",
       " 'activity_Nonproduction_frac_total_entropy': 0.0,\n",
       " 'activity_Input_frac_total_entropy': 0.0,\n",
       " 'activity_Remove/Cut_frac_total_entropy': 0.0,\n",
       " 'activity_Replace_frac_total_entropy': 0.0,\n",
       " 'activity_Paste_frac_total_entropy': 0.0,\n",
       " 'activity_Move_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Input_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Replace_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Paste_frac_total_entropy': 0.0,\n",
       " 'is_new_burst_start_Move_frac_total_entropy': 0.0,\n",
       " 'is_thought_delimiting_punctuation_frac_total_entropy': 0.0,\n",
       " 'word_count_delta_event_frac_total_entropy': 0.0,\n",
       " 'preceding_pause_time_frac_total_entropy': 0.0,\n",
       " 'activity_Nonproduction_stddev': 0.0,\n",
       " 'activity_Input_stddev': 0.0,\n",
       " 'activity_Remove/Cut_stddev': 0.0,\n",
       " 'activity_Replace_stddev': 0.0,\n",
       " 'activity_Paste_stddev': 0.0,\n",
       " 'activity_Move_stddev': 0.0,\n",
       " 'is_new_burst_start_stddev': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_stddev': 0.0,\n",
       " 'is_new_burst_start_Input_stddev': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_stddev': 0.0,\n",
       " 'is_new_burst_start_Replace_stddev': 0.0,\n",
       " 'is_new_burst_start_Paste_stddev': 0.0,\n",
       " 'is_new_burst_start_Move_stddev': 0.0,\n",
       " 'is_thought_delimiting_punctuation_stddev': 0.0,\n",
       " 'delete_insert_ratio_stddev': 0.0,\n",
       " 'activity_Nonproduction_time_norm_stddev': 0.0,\n",
       " 'activity_Input_time_norm_stddev': 0.0,\n",
       " 'activity_Remove/Cut_time_norm_stddev': 0.0,\n",
       " 'activity_Replace_time_norm_stddev': 0.0,\n",
       " 'activity_Paste_time_norm_stddev': 0.0,\n",
       " 'activity_Move_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Input_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Replace_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Paste_time_norm_stddev': 0.0,\n",
       " 'is_new_burst_start_Move_time_norm_stddev': 0.0,\n",
       " 'is_thought_delimiting_punctuation_time_norm_stddev': 0.0,\n",
       " 'activity_Nonproduction_frac_total_stddev': 0.0,\n",
       " 'activity_Input_frac_total_stddev': 0.0,\n",
       " 'activity_Remove/Cut_frac_total_stddev': 0.0,\n",
       " 'activity_Replace_frac_total_stddev': 0.0,\n",
       " 'activity_Paste_frac_total_stddev': 0.0,\n",
       " 'activity_Move_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Input_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Replace_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Paste_frac_total_stddev': 0.0,\n",
       " 'is_new_burst_start_Move_frac_total_stddev': 0.0,\n",
       " 'is_thought_delimiting_punctuation_frac_total_stddev': 0.0,\n",
       " 'word_count_delta_event_stddev': 0.0,\n",
       " 'preceding_pause_time_stddev': 0.0,\n",
       " 'word_count_delta_event_frac_total_stddev': 0.0,\n",
       " 'preceding_pause_time_frac_total_stddev': 0.0,\n",
       " 'cursor_position_vs_max_stddev': 0.0,\n",
       " 'activity_Nonproduction_ttrend': 0.0,\n",
       " 'activity_Input_ttrend': 0.0,\n",
       " 'activity_Remove/Cut_ttrend': 0.0,\n",
       " 'activity_Replace_ttrend': 0.0,\n",
       " 'activity_Paste_ttrend': 0.0,\n",
       " 'activity_Move_ttrend': 0.0,\n",
       " 'is_new_burst_start_ttrend': 0.0,\n",
       " 'is_new_burst_start_Nonproduction_ttrend': 0.0,\n",
       " 'is_new_burst_start_Input_ttrend': 0.0,\n",
       " 'is_new_burst_start_Remove/Cut_ttrend': 0.0,\n",
       " 'is_new_burst_start_Replace_ttrend': 0.0,\n",
       " 'is_new_burst_start_Paste_ttrend': 0.0,\n",
       " 'is_new_burst_start_Move_ttrend': 0.0,\n",
       " 'is_thought_delimiting_punctuation_ttrend': 0.0,\n",
       " 'delete_insert_ratio_ttrend': 0.0,\n",
       " 'word_count_delta_event_ttrend': 0.0,\n",
       " 'preceding_pause_time_ttrend': 0.0,\n",
       " 'cursor_position_vs_max_ttrend': 0.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform.isnull().mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_transform\n",
    "    .to_pickle(\"./data/processed/X_train.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train\n",
    "    .loc[X_train['id'].isin(['b732c6e2', 'b73648cf'])]\n",
    "    .to_csv(\"./data/X_train_enriched_cases.csv\", index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
