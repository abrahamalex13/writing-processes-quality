{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_PER_S = 1000\n",
    "PATH_TRAIN_LOGS = \"./data/external/train_logs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "\n",
    "    X = pd.read_csv(path)\n",
    "    X = X.sort_values([\"id\", \"event_id\"], ascending=[True, True])\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_activity(X):\n",
    "\n",
    "    # 'Move From' activity recorded with low-level cursor loc details\n",
    "    # extract bigger-picture 'Move From'\n",
    "    # QUESTION: what's the difference between Move From, and a cut+paste?\n",
    "    X['activity_detailed'] = X['activity']\n",
    "    X.loc[X['activity'].str.contains('Move From'), 'activity'] = 'Move'\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAUSE_THRESHOLD_MS = 1000\n",
    "N_ACTIVITIES_UNTIL_START_WINDOW_CLOSES = 100\n",
    "\n",
    "def enrich_pauses(X):\n",
    "    \"\"\"Must infer pauses, as no explicit record indicates.\"\"\"\n",
    "\n",
    "    X['up_time_lag1'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['up_time']\n",
    "        .shift(1)\n",
    "        )\n",
    "    # latency does not mean a meaningful pause\n",
    "    X['latency_time'] = (\n",
    "        X['down_time'] - X['up_time_lag1']\n",
    "        )\n",
    "\n",
    "    X['preceding_pause_time'] = X['latency_time']\n",
    "    # first record lacks preceding_pause_time: that's time before first key press\n",
    "    X.loc[X['event_id'] == 1, 'preceding_pause_time'] = X['down_time']\n",
    "    # expect some negative pause times -- interpret as, no real pause\n",
    "    has_no_real_pause = X['preceding_pause_time'] <= PAUSE_THRESHOLD_MS\n",
    "    X.loc[has_no_real_pause, 'preceding_pause_time'] = None\n",
    "    # not obvious how to tag \"initial planning pause\" \n",
    "    # tried \"first 5 minutes\", but when that pause is 10 minutes, that fails.\n",
    "    # first XX minutes is fragile\n",
    "    # first XX events may help -- what's your extent of pause before *action*?\n",
    "    X['preceding_pause_time_start_window'] = X['preceding_pause_time']\n",
    "    X.loc[X['event_id'] <= N_ACTIVITIES_UNTIL_START_WINDOW_CLOSES, 'preceding_pause_time_start_window'] = None\n",
    "\n",
    "    X['total_pause_time'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['preceding_pause_time']\n",
    "        .transform('sum')\n",
    "        )\n",
    "    X['rolling_pause_time'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['preceding_pause_time']\n",
    "        .cumsum()\n",
    "        )\n",
    "    X['rolling_pause_time_fraction'] = (\n",
    "        X['rolling_pause_time'] / X['total_pause_time']\n",
    "        )\n",
    "\n",
    "    # summarize pause distr\n",
    "    # MS_IN_PAUSE_BUCKET_MAX = 200e3\n",
    "    # PAUSE_BUCKET_STEP_MS = 500\n",
    "    # X['preceding_pause_time_bucket'] = pd.cut(\n",
    "    #     X['preceding_pause_time'],\n",
    "    #     bins=np.arange(\n",
    "    #         0, \n",
    "    #         MS_IN_PAUSE_BUCKET_MAX,\n",
    "    #         PAUSE_BUCKET_STEP_MS\n",
    "    #         )\n",
    "    #     )\n",
    "    # X['preceding_pause_time_bucket'].value_counts()\n",
    "    # WARNING: this representation of pause distribution is dense & large\n",
    "    # a few parameters from distribution model far more succinct\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pause exceeds threshold duration, a \"burst\" has ended\n",
    "SECONDS_PER_BURST = 2\n",
    "\n",
    "def enrich_time_bursts(X):\n",
    "\n",
    "    X['is_new_burst_start'] = (\n",
    "        X['preceding_pause_time'] > MS_PER_S * SECONDS_PER_BURST\n",
    "        ).astype(int)\n",
    "    X.loc[X['event_id'] == 1, 'is_new_burst_start'] = 1\n",
    "    X['burst_id'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['is_new_burst_start']\n",
    "        .cumsum()\n",
    "        )\n",
    "    X['burst_time_start'] = (\n",
    "        X\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['down_time']\n",
    "        .transform('min')\n",
    "        )\n",
    "    X['burst_time_end'] = (\n",
    "        X\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['up_time']\n",
    "        .transform('max')\n",
    "        )\n",
    "    X['burst_time_duration'] = (\n",
    "        X['burst_time_end'] - X['burst_time_start']\n",
    "        )\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_activity_streaks(X):\n",
    "        \n",
    "    # consecutive activity (independent of time) suggests productive writing flow\n",
    "\n",
    "    X['activity_lag1'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['activity']\n",
    "        .shift(1)\n",
    "        )\n",
    "\n",
    "    X['is_new_activity_streak_start'] = (\n",
    "        X['activity'] != X['activity_lag1']\n",
    "    ).astype(int)\n",
    "    X.loc[X['event_id'] == 1, 'is_new_activity_streak_start'] = 1\n",
    "\n",
    "    X['is_activity_streak_end'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['is_new_activity_streak_start']\n",
    "        .shift(-1)\n",
    "        )\n",
    "    X['is_activity_streak_end'] = X['is_activity_streak_end'].fillna(1) \n",
    "\n",
    "    X['activity_streak_id'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['is_new_activity_streak_start']\n",
    "        .cumsum()\n",
    "    )\n",
    "\n",
    "    X['activity_streak_length_thin'] = (\n",
    "        X\n",
    "        .groupby(['id', 'activity_streak_id'])\n",
    "        .transform('size')\n",
    "    )\n",
    "    X.loc[X['is_activity_streak_end'] == 0, 'activity_streak_length_thin'] = None\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_word_count(X):\n",
    "\n",
    "    # word count offers a productivity measure\n",
    "    X['word_count_lag1'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['word_count']\n",
    "        .shift(1)\n",
    "        )\n",
    "\n",
    "    X['word_count_delta_event'] = (\n",
    "        X['word_count'] - X['word_count_lag1']\n",
    "        )\n",
    "\n",
    "    X['word_count_delta_burst'] = (\n",
    "        X\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['word_count_delta_event']\n",
    "        .transform('sum')\n",
    "        )\n",
    "    # de-duplicate to one value per burst -- easier for downstream aggregation\n",
    "    X['word_count_delta_burst_thin'] = X['word_count_delta_burst']\n",
    "    X.loc[X['is_new_burst_start'] == 0, 'word_count_delta_burst_thin'] = None\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_cursor_position(X):\n",
    "\n",
    "    # one-way cursor movement might be most productive\n",
    "    # jumping around is choppy\n",
    "    X['cursor_position_lag1'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['cursor_position']\n",
    "        .shift(1)\n",
    "        )\n",
    "\n",
    "    X['has_cursor_position_moved_right'] = (\n",
    "        X['cursor_position'] > X['cursor_position_lag1']\n",
    "        ).astype(int)\n",
    "\n",
    "    # if cursor position increases due to copy+paste (perhaps of essay prompt),\n",
    "    # that doesn't reflect grade-driving output\n",
    "    X['cursor_position_input'] = np.where(\n",
    "        X['activity'] == \"Input\", \n",
    "        X[\"cursor_position\"], \n",
    "        np.nan\n",
    "        )\n",
    "    X['cursor_position_cummax'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['cursor_position_input']\n",
    "        .cummax()\n",
    "        )\n",
    "    # for some reason, unable to chain below statements with above\n",
    "    X['cursor_position_cummax'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['cursor_position_cummax']\n",
    "        .ffill()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    X['cursor_position_vs_max'] = (\n",
    "        X['cursor_position'] - X['cursor_position_cummax']\n",
    "        )\n",
    "\n",
    "    X['cursor_position_last_space'] = np.where(\n",
    "        (X['activity'] == \"Input\") & (X[\"text_change\"] == ' '),\n",
    "        X['cursor_position'],\n",
    "        np.nan\n",
    "    ) \n",
    "    X['cursor_position_last_space'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['cursor_position_last_space']\n",
    "        .ffill()\n",
    "        # likely not beginning essay with a space\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    X = X.drop(columns='cursor_position_input')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_word_length(X):\n",
    "        \n",
    "    # word length offers a content quality measure.\n",
    "    # hard to track entire words sequence in rolling fashion.\n",
    "        # every word's length, in a list of one element per word?  \n",
    "    # more tractable to track very latest string\n",
    "\n",
    "    is_edit_to_latest_string = (\n",
    "        X['cursor_position'] > X['cursor_position_last_space']\n",
    "    )\n",
    "\n",
    "    X['is_latest_space'] = (\n",
    "        (X['cursor_position_vs_max'] == 0)\n",
    "        & (X['activity'] == \"Input\")\n",
    "        & (X[\"text_change\"] == ' ')\n",
    "        )\n",
    "\n",
    "    X['is_latest_string_end'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['is_latest_space']\n",
    "        .shift(-1)\n",
    "        # last process records\n",
    "        .fillna(True)\n",
    "        )\n",
    "\n",
    "    X['n_alphanum_char_added_to_latest_string'] = 0\n",
    "    is_alphanumeric_addition = (\n",
    "        (X['activity'] == \"Input\")\n",
    "        & (X[\"text_change\"] == 'q')\n",
    "        )\n",
    "    X.loc[\n",
    "        (is_alphanumeric_addition & is_edit_to_latest_string), \n",
    "        'n_alphanum_char_added_to_latest_string'\n",
    "        ] = 1\n",
    "    is_alphanumeric_subtraction = (\n",
    "        (X['activity'] == \"Remove/Cut\")\n",
    "        & (X['up_event'] == 'Backspace')\n",
    "        & (X[\"text_change\"] == 'q')\n",
    "        )\n",
    "    X.loc[\n",
    "        (is_alphanumeric_subtraction & is_edit_to_latest_string), \n",
    "        'n_alphanum_char_added_to_latest_string'\n",
    "        ] = -1\n",
    "\n",
    "    # example: 2nd string, 2 characters in.\n",
    "    # considering cumsum for each character in 2nd string, \n",
    "    # subtract those characters from 1st\n",
    "    X['rolling_length_strings'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['n_alphanum_char_added_to_latest_string']\n",
    "        .cumsum() \n",
    "        ) \n",
    "\n",
    "    X['rolling_length_completed_strings'] = None\n",
    "    X.loc[\n",
    "        X['is_latest_space'], 'rolling_length_completed_strings'\n",
    "        ] = X['rolling_length_strings']\n",
    "    X['rolling_length_completed_strings'] = (\n",
    "        X\n",
    "        .groupby(['id'])\n",
    "        ['rolling_length_completed_strings']\n",
    "        .ffill()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    X['rolling_length_latest_string'] = (\n",
    "        X['rolling_length_strings'] \n",
    "        - X['rolling_length_completed_strings']\n",
    "    )\n",
    "\n",
    "    X['length_latest_string'] = None\n",
    "    X.loc[\n",
    "        X['is_latest_string_end'], 'length_latest_string'\n",
    "        ] = X['rolling_length_latest_string']\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_punctuation(X):\n",
    "        \n",
    "    # if thoughts aren't separated by punctuation, writing won't score well\n",
    "    X['is_thought_delimiting_punctuation'] = (\n",
    "        (X['text_change'] == \".\")\n",
    "        | (X['text_change'] == \". \")\n",
    "        | (X['text_change'] == \",\")\n",
    "        | (X['text_change'] == \"-\")\n",
    "        | (X['text_change'] == \"!\")\n",
    "        | (X['text_change'] == \";\")\n",
    "        | (X['text_change'] == \"?\")\n",
    "        | (X['text_change'] == \":\")\n",
    "        ).astype(int)\n",
    "\n",
    "    X['is_special_punctuation'] = (\n",
    "        (X['text_change'] == \"=\")\n",
    "        | (X['text_change'] == \"/\")\n",
    "        | (X['text_change'] == \"\\\\\")\n",
    "        | (X['text_change'] == \"(\")\n",
    "        | (X['text_change'] == \")\")\n",
    "        | (X['text_change'] == \"\\n\")\n",
    "        | (X['text_change'] == \"[\")\n",
    "        | (X['text_change'] == \"]\")\n",
    "        | (X['text_change'] == \">\")\n",
    "        | (X['text_change'] == \"<\")\n",
    "        | (X['text_change'] == \"$\")\n",
    "        | (X['text_change'] == \"*\")\n",
    "        | (X['text_change'] == \"&\")\n",
    "    )\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_MIN_MAX_EXPECTED = 30\n",
    "TOTAL_MIN_PLUS_BUFFER = 150 # id 21bbc3f6 case extended to 140 min ... odd\n",
    "SECONDS_PER_MIN = 60\n",
    "SECONDS_PER_WINDOW = 30\n",
    "\n",
    "def enrich_time_windows(X):\n",
    "\n",
    "    # windows allow for time-sequence features\n",
    "    # expect that some essays extend beyond 30 min described in 'Data Collection'\n",
    "    # downstream, **do not tabulate over a writer's unused time windows**!!\n",
    "\n",
    "    X['window_30s'] = pd.cut(\n",
    "        X['down_time'],\n",
    "        bins=np.arange(\n",
    "            0, \n",
    "            TOTAL_MIN_PLUS_BUFFER * SECONDS_PER_MIN * MS_PER_S, \n",
    "            SECONDS_PER_WINDOW * MS_PER_S\n",
    "            )\n",
    "        )\n",
    "\n",
    "    X['is_time_beyond_expected_max'] = (\n",
    "        X['up_time'] > TOTAL_MIN_MAX_EXPECTED * SECONDS_PER_MIN * MS_PER_S\n",
    "    ).astype(int)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CATEGORIES = ['Nonproduction', 'Input', 'Remove/Cut', 'Replace', 'Paste', 'Move']\n",
    "\n",
    "def transform_activity_onehot(X, is_training_run):\n",
    "\n",
    "    if is_training_run:\n",
    "\n",
    "        pipeline = ColumnTransformer(\n",
    "            transformers=[(\n",
    "                'onehot_encode', \n",
    "                preprocessing.OneHotEncoder(\n",
    "                    categories=[ACTIVITY_CATEGORIES], \n",
    "                    sparse=False, \n",
    "                    handle_unknown='infrequent_if_exist'\n",
    "                    ),\n",
    "                [\"activity\"]\n",
    "            )],\n",
    "            remainder='passthrough',\n",
    "            verbose_feature_names_out=False\n",
    "            )\n",
    "        \n",
    "        pipeline.fit(X)\n",
    "\n",
    "        with open(\"pipeline_activity_onehot.pkl\", \"wb\") as f:\n",
    "            pickle.dump(pipeline, f)\n",
    "\n",
    "    else:\n",
    "        with open(\"pipeline_activity_onehot.pkl\", \"rb\") as f:\n",
    "            pipeline = pickle.load(f)\n",
    "\n",
    "    original_categorical = X['activity']\n",
    "\n",
    "    X_dtypes = X.dtypes.to_dict()\n",
    "    X = pipeline.transform(X)\n",
    "    X = pd.DataFrame(X, columns=pipeline.get_feature_names_out())\n",
    "    X = pd.concat([X, original_categorical], axis=1)\n",
    "    X = X.astype(X_dtypes)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_burst_type(X):\n",
    "\n",
    "    for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "        X['burst_events_' + activity] = (\n",
    "            X\n",
    "            .groupby(['id', 'burst_id'])\n",
    "            ['activity_' + activity]\n",
    "            .transform('sum')\n",
    "            ).astype(float)\n",
    "        \n",
    "    X['burst_type'] = (\n",
    "        X\n",
    "        [['burst_events_' + activity for activity in ACTIVITY_CATEGORIES]]\n",
    "        .idxmax(axis=1)\n",
    "        )\n",
    "    X['burst_type'] = (\n",
    "        X['burst_type']\n",
    "        .str\n",
    "        .replace(\"burst_events_\", \"\", regex=True)\n",
    "        )\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_burst_type_onehot(X, is_training_run):\n",
    "\n",
    "    if is_training_run:\n",
    "        \n",
    "        pipeline = ColumnTransformer(\n",
    "            transformers=[(\n",
    "                'onehot_encode', \n",
    "                preprocessing.OneHotEncoder(\n",
    "                    categories=[ACTIVITY_CATEGORIES], \n",
    "                    sparse=False, \n",
    "                    handle_unknown='infrequent_if_exist'\n",
    "                    ),\n",
    "                [\"burst_type\"]\n",
    "            )],\n",
    "            remainder='passthrough',\n",
    "            verbose_feature_names_out=False\n",
    "            )\n",
    "        \n",
    "        pipeline.fit(X)\n",
    "        \n",
    "        with open(\"pipeline_burst_type_onehot.pkl\", \"wb\") as f:\n",
    "            pickle.dump(pipeline, f)\n",
    "\n",
    "    else:\n",
    "        with open(\"pipeline_burst_type_onehot.pkl\", \"rb\") as f:\n",
    "            pipeline = pickle.load(f)\n",
    "\n",
    "    original_categorical = X['burst_type']\n",
    "    X_dtypes = X.dtypes.to_dict()\n",
    "    X = pipeline.transform(X)\n",
    "    X = pd.DataFrame(X, columns=pipeline.get_feature_names_out())\n",
    "    X = pd.concat([X, original_categorical], axis=1)\n",
    "    X = X.astype(X_dtypes)\n",
    "\n",
    "    for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "        X['is_new_burst_start_' + activity] = (\n",
    "            X['is_new_burst_start'] * \n",
    "            X['burst_type_' + activity]\n",
    "            )\n",
    "        \n",
    "        X['is_new_activity_streak_start_' + activity] = (\n",
    "            X[\"activity_\" + activity] * X['is_new_activity_streak_start']\n",
    "        )\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_features(X):\n",
    "\n",
    "    return X[[\n",
    "        \"id\",\n",
    "        \"event_id\",\n",
    "        \"is_time_beyond_expected_max\",\n",
    "        \"window_30s\",\n",
    "        \"burst_id\",\n",
    "        \"burst_type\",\n",
    "        \"burst_type_Nonproduction\",\n",
    "        \"burst_type_Input\",\n",
    "        \"burst_type_Remove/Cut\",\n",
    "        \"burst_type_Replace\",\n",
    "        \"burst_type_Paste\",\n",
    "        \"burst_type_Move\",\n",
    "        \"is_new_burst_start\",\n",
    "        \"is_new_burst_start_Nonproduction\",\n",
    "        \"is_new_burst_start_Input\",\n",
    "        \"is_new_burst_start_Remove/Cut\",\n",
    "        \"is_new_burst_start_Replace\",\n",
    "        \"is_new_burst_start_Paste\",\n",
    "        \"is_new_burst_start_Move\",\n",
    "        \"burst_time_start\",\n",
    "        \"burst_time_end\",\n",
    "        \"burst_time_duration\",\n",
    "        \"burst_events_Nonproduction\",\n",
    "        \"burst_events_Input\",\n",
    "        \"burst_events_Remove/Cut\",\n",
    "        \"burst_events_Replace\",\n",
    "        \"burst_events_Paste\",\n",
    "        \"burst_events_Move\",\n",
    "        \"word_count_delta_burst\",\n",
    "        \"word_count_delta_burst_thin\",\n",
    "        \"activity_streak_id\",\n",
    "        \"is_new_activity_streak_start\",\n",
    "        \"is_new_activity_streak_start_Nonproduction\",\n",
    "        \"is_new_activity_streak_start_Input\",\n",
    "        \"is_new_activity_streak_start_Remove/Cut\",\n",
    "        \"is_new_activity_streak_start_Replace\",\n",
    "        \"is_new_activity_streak_start_Paste\",\n",
    "        \"is_new_activity_streak_start_Move\",\n",
    "        \"is_activity_streak_end\",\n",
    "        \"activity_streak_length_thin\",\n",
    "\n",
    "        \"down_time\",\n",
    "        \"up_time\",\t\n",
    "        \"action_time\",\t\n",
    "        \"activity_detailed\",\n",
    "        \"activity\",\t\n",
    "        \"activity_Nonproduction\",\n",
    "        \"activity_Input\",\n",
    "        \"activity_Remove/Cut\",\n",
    "        \"activity_Replace\",\n",
    "        \"activity_Paste\",\n",
    "        \"activity_Move\",\n",
    "        \"down_event\",\t\n",
    "        \"up_event\",\t\n",
    "        \"text_change\",\n",
    "        \"is_thought_delimiting_punctuation\",\n",
    "        \"cursor_position\",\t\n",
    "        \"word_count\",\n",
    "\n",
    "        \"cursor_position_vs_max\",\n",
    "        \"cursor_position_cummax\",\n",
    "        \"has_cursor_position_moved_right\",\n",
    "        \"cursor_position_last_space\",\n",
    "\n",
    "        \"is_latest_space\",\n",
    "        \"is_latest_string_end\",\n",
    "        \"n_alphanum_char_added_to_latest_string\",\n",
    "        \"rolling_length_latest_string\",\n",
    "        \"length_latest_string\",\n",
    "\n",
    "        \"word_count_lag1\",\n",
    "        \"word_count_delta_event\",\n",
    "\n",
    "        \"up_time_lag1\",\n",
    "        \"latency_time\",\n",
    "        \"preceding_pause_time\",\n",
    "        \"preceding_pause_time_start_window\",\n",
    "        \"rolling_pause_time\",\n",
    "        \"rolling_pause_time_fraction\",\n",
    "        \"total_pause_time\"\n",
    "        ]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_logs(X, is_training_run):\n",
    "\n",
    "#     PUNCTUATION = X_train.loc[(\n",
    "#         (X_train['activity'] == 'Input')\n",
    "#         & (~ X_train['text_change'].isin(['q', ' ']))\n",
    "#         ), 'text_change'].unique()\n",
    "\n",
    "    X = scrub_activity(X)\n",
    "\n",
    "    X = enrich_pauses(X)\n",
    "\n",
    "    X = enrich_time_bursts(X)\n",
    "\n",
    "    X = enrich_activity_streaks(X)\n",
    "\n",
    "    X = enrich_word_count(X)\n",
    "\n",
    "    X = enrich_cursor_position(X)\n",
    "\n",
    "    X = enrich_word_length(X)\n",
    "\n",
    "    X = enrich_punctuation(X)\n",
    "\n",
    "    X = enrich_time_windows(X)\n",
    "\n",
    "    print(\"Proceeding to activity onehot encode.\")\n",
    "    X = transform_activity_onehot(X, is_training_run)\n",
    "    print(\"Completed activity onehot encode.\")\n",
    "\n",
    "    X = enrich_burst_type(X)\n",
    "\n",
    "    print(\"Proceeding to burst type onehot encode\")\n",
    "    X = transform_burst_type_onehot(X, is_training_run)\n",
    "    print(\"Completed burst type onehot encode\")\n",
    "\n",
    "    return subset_features(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_vars_sum = (\n",
    "    ['activity_' + x for x in ACTIVITY_CATEGORIES] \n",
    "    + ['is_new_burst_start'] \n",
    "    + ['is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    + [\"is_thought_delimiting_punctuation\"]\n",
    "    + [\"is_new_activity_streak_start_\" + x for x in ACTIVITY_CATEGORIES]\n",
    "    )\n",
    "\n",
    "conti_vars_sum = (\n",
    "    ['word_count_delta_event']\n",
    "    + [\"preceding_pause_time\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def aggregate_no_time_dependence_measures(X):\n",
    "\n",
    "    events_sum_over_time = (\n",
    "        X\n",
    "        .groupby('id')\n",
    "        [event_vars_sum]\n",
    "        .agg(sum)\n",
    "        )\n",
    "\n",
    "    events_sum_over_time['delete_insert_ratio'] = (\n",
    "        events_sum_over_time['activity_Remove/Cut'] / \n",
    "        events_sum_over_time['activity_Input'] \n",
    "        )\n",
    "\n",
    "    conti_sum_over_time = (\n",
    "        X\n",
    "        .groupby('id')\n",
    "        [conti_vars_sum]\n",
    "        .agg(sum)\n",
    "        )\n",
    "\n",
    "    sums_over_time = pd.merge(\n",
    "        events_sum_over_time,\n",
    "        conti_sum_over_time,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "    centrals_over_time = (\n",
    "        X\n",
    "        .groupby('id')\n",
    "        .agg(\n",
    "            latency_time_p50 = ('latency_time', np.median),\n",
    "            pause_time_p50 = ('preceding_pause_time', np.median),\n",
    "            has_cursor_position_moved_right_mean = ('has_cursor_position_moved_right', 'mean'),\n",
    "            word_count_delta_burst_mean = ('word_count_delta_burst_thin', 'mean'),\n",
    "            word_count_delta_burst_p50 = ('word_count_delta_burst_thin', np.median),\n",
    "            activity_streak_length_mean = ('activity_streak_length_thin', 'mean'),\n",
    "            cursor_position_vs_max_avg = ('cursor_position_vs_max', 'mean'),\n",
    "            length_latest_string_mean = ('length_latest_string', 'mean'),\n",
    "            length_latest_string_stddev = ('length_latest_string', np.std)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "\n",
    "    extremes_over_time = (\n",
    "        X\n",
    "        .groupby('id')\n",
    "        .agg(\n",
    "            pause_time_max=('preceding_pause_time', 'max'),\n",
    "            initial_pause_time_max=('preceding_pause_time_start_window', 'max'),\n",
    "            # approximation to, next longest pause after first long planning pause\n",
    "            pause_time_p99=('preceding_pause_time', lambda x: x.quantile(0.99)),\n",
    "            word_count_delta_burst_max=('word_count_delta_burst_thin', 'max'),\n",
    "            activity_streak_length_max=('activity_streak_length_thin', 'max'),\n",
    "            total_time=('up_time', 'max'),\n",
    "            length_latest_string_max=('length_latest_string', 'max'),\n",
    "            latency_time_min=('latency_time', 'min'),\n",
    "            is_time_beyond_expected_max=('is_time_beyond_expected_max', 'max')\n",
    "            )\n",
    "        )\n",
    "\n",
    "    extremes_over_time['is_initial_pause_max_pause'] = (\n",
    "        extremes_over_time['pause_time_max'] == \n",
    "        extremes_over_time['initial_pause_time_max']\n",
    "        ).astype(int)\n",
    "    \n",
    "\n",
    "    from scipy.stats import lognorm\n",
    "\n",
    "    pause_distr_summary_subjects = []\n",
    "\n",
    "    for X_subject in [x for _, x in X.groupby('id')]:\n",
    "\n",
    "        shape, location, scale = lognorm.fit(X_subject['preceding_pause_time'].dropna())\n",
    "\n",
    "        pause_distr_summary = pd.DataFrame({\n",
    "            'pauses_lognorm_shape': [shape], \n",
    "            'pauses_lognorm_location': [location],\n",
    "            'pauses_lognorm_scale': [scale]\n",
    "            })\n",
    "        pause_distr_summary.index = [X_subject['id'].iloc[0]]\n",
    "        \n",
    "        pause_distr_summary_subjects.append(pause_distr_summary)\n",
    "\n",
    "    distr_params_over_time = pd.concat(pause_distr_summary_subjects, axis=0)\n",
    "\n",
    "\n",
    "    aggregates_over_time = pd.merge(\n",
    "        sums_over_time, \n",
    "        centrals_over_time,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )\n",
    "\n",
    "    aggregates_over_time = pd.merge(\n",
    "        aggregates_over_time, \n",
    "        extremes_over_time,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )\n",
    "\n",
    "    aggregates_over_time = pd.merge(\n",
    "        aggregates_over_time, \n",
    "        distr_params_over_time,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )\n",
    "    \n",
    "\n",
    "    for var in event_vars_sum:\n",
    "\n",
    "        aggregates_over_time[var + '_per_s'] = (\n",
    "            1000 * (aggregates_over_time[var] / aggregates_over_time['total_time'])\n",
    "            )\n",
    "\n",
    "    aggregates_over_time = (\n",
    "        aggregates_over_time\n",
    "        .assign(\n",
    "            keystroke_speed = lambda x: (x.activity_Input + x['activity_Remove/Cut']) / x.total_time,\n",
    "            words_per_thought_delimiting_punctuation = lambda x: x.word_count_delta_event / x.is_thought_delimiting_punctuation,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return aggregates_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_time_variability_measures(aggregates_over_time, X):\n",
    "\n",
    "    # per writer, by default, tabulate _every_ time window ever observed in data.\n",
    "    # override: tabulate strictly until writer's final utilized time window.\n",
    "    events_by_window = (\n",
    "        X\n",
    "        .groupby(['id', 'window_30s'])\n",
    "        [event_vars_sum]\n",
    "        .agg(sum)\n",
    "        .astype(float)\n",
    "        .fillna(0)\n",
    "        .reset_index(drop=False)\n",
    "        )\n",
    "    events_by_window['has_activity'] = (\n",
    "        events_by_window[['activity_' + x for x in ACTIVITY_CATEGORIES]].sum(axis=1) \n",
    "        > 0\n",
    "    )\n",
    "    events_by_window['idx_window_by_id'] = (\n",
    "        events_by_window\n",
    "        .groupby('id')\n",
    "        .cumcount()\n",
    "    )\n",
    "    events_by_window['idx_has_activity'] = np.where(\n",
    "        events_by_window['has_activity'], \n",
    "        events_by_window['idx_window_by_id'],\n",
    "        np.nan\n",
    "        )\n",
    "    events_by_window['idx_activity_max'] = (\n",
    "        events_by_window\n",
    "        .groupby(['id'])\n",
    "        ['idx_has_activity']\n",
    "        .transform('max')\n",
    "    )\n",
    "    events_by_window = events_by_window.loc[\n",
    "        events_by_window['idx_window_by_id'] <= events_by_window['idx_activity_max']\n",
    "        ]\n",
    "    events_by_window = events_by_window.drop(\n",
    "        columns=['has_activity', 'idx_has_activity', 'idx_activity_max']\n",
    "        )\n",
    "\n",
    "    events_by_window['delete_insert_ratio'] = (\n",
    "        events_by_window['activity_Remove/Cut'] / \n",
    "        events_by_window['activity_Input'] \n",
    "        ).replace(np.inf, np.nan)\n",
    "\n",
    "\n",
    "    # for variability measure more comparable between writers, de-mean by writer. \n",
    "    # Ex: higher-throughput writer incurs higher stddev, because values have higher magnitude\n",
    "    # join method allows for merge on one index column, of multiple possible\n",
    "    events_by_window = events_by_window.join(\n",
    "        aggregates_over_time[[x + '_per_s' for x in event_vars_sum]],\n",
    "        on='id',\n",
    "        how='left'\n",
    "        )\n",
    "    for var in event_vars_sum:\n",
    "        events_by_window[var + '_time_norm'] = (\n",
    "            events_by_window[var] / \n",
    "            (events_by_window[var + '_per_s'].replace(0, None) * 30)\n",
    "            ).fillna(1)\n",
    "    events_by_window = events_by_window.drop(columns=[x + '_per_s' for x in event_vars_sum])\n",
    "\n",
    "    events_over_time_ren = aggregates_over_time[event_vars_sum]\n",
    "    events_over_time_ren.columns = [x + \"_total\" for x in events_over_time_ren.columns]\n",
    "    events_by_window = events_by_window.join(events_over_time_ren, on='id', how='left')\n",
    "    for var in event_vars_sum:\n",
    "        events_by_window[var + '_frac_total'] = (\n",
    "            events_by_window[var] / (events_by_window[var + '_total'].replace(0, None))\n",
    "            ).fillna(1)\n",
    "    events_by_window = events_by_window.drop(columns=[x + '_total' for x in event_vars_sum])\n",
    "\n",
    "\n",
    "    conti_by_window = (\n",
    "        X\n",
    "        .assign()\n",
    "        .groupby(['id', 'window_30s'])\n",
    "        [conti_vars_sum]\n",
    "        .agg(sum)\n",
    "        .astype(float)\n",
    "        .fillna(0)\n",
    "        .reset_index(drop=False)\n",
    "        )\n",
    "    conti_by_window['idx_window_by_id'] = (\n",
    "        conti_by_window\n",
    "        .groupby('id')\n",
    "        .cumcount()\n",
    "    )\n",
    "\n",
    "    conti_over_time_ren = aggregates_over_time[conti_vars_sum]\n",
    "    conti_over_time_ren.columns = [x + \"_total\" for x in conti_over_time_ren.columns]\n",
    "    conti_by_window = conti_by_window.join(conti_over_time_ren, on='id', how='left')\n",
    "    for var in conti_vars_sum:\n",
    "        conti_by_window[var + '_frac_total'] = (\n",
    "            conti_by_window[var] / conti_by_window[var + '_total']\n",
    "            )\n",
    "    conti_by_window = conti_by_window.drop(columns=[x + '_total' for x in conti_vars_sum])\n",
    "\n",
    "\n",
    "    centrals_by_window = (\n",
    "        X\n",
    "        .groupby(['id', 'window_30s'])\n",
    "        ['cursor_position_vs_max']\n",
    "        .agg('mean')\n",
    "        .astype(float)\n",
    "        .reset_index(drop=False)\n",
    "        )\n",
    "    centrals_by_window['idx_window_by_id'] = (\n",
    "        centrals_by_window\n",
    "        .groupby('id')\n",
    "        .cumcount()\n",
    "    )\n",
    "\n",
    "\n",
    "    aggregates_by_window = pd.merge(\n",
    "        events_by_window, \n",
    "        conti_by_window,\n",
    "        # events table reflects, writer's final utilized time window.\n",
    "        # not all possible\n",
    "        how='inner'\n",
    "        )\n",
    "\n",
    "    aggregates_by_window = pd.merge(\n",
    "        aggregates_by_window, \n",
    "        centrals_by_window,\n",
    "        how='left'\n",
    "        )\n",
    "    \n",
    "\n",
    "    from scipy.stats import entropy\n",
    "\n",
    "    entropy_vars = [var for var in aggregates_by_window.columns if 'frac_total' in var]\n",
    "    entropy_by_window = (\n",
    "        aggregates_by_window\n",
    "        .groupby(['id'])\n",
    "        [entropy_vars]\n",
    "        .agg(lambda x: entropy(x.value_counts()))\n",
    "        )\n",
    "    entropy_by_window.columns = [\n",
    "        x + '_entropy' \n",
    "        for x in entropy_by_window.columns\n",
    "        ]\n",
    "\n",
    "\n",
    "    sd_by_window = (\n",
    "        aggregates_by_window\n",
    "        .drop(columns=['window_30s', 'idx_window_by_id'])\n",
    "        .groupby(['id'])\n",
    "        .agg(np.std)\n",
    "        )\n",
    "    sd_by_window.columns = [\n",
    "        x + \"_stddev\"\n",
    "        for x in sd_by_window.columns\n",
    "        ]\n",
    "\n",
    "\n",
    "    trend_by_window = (\n",
    "        aggregates_by_window\n",
    "        .sort_values(['id', 'idx_window_by_id'])\n",
    "        .drop(columns=['window_30s'])\n",
    "        .groupby(['id'])\n",
    "        .corr()\n",
    "        )\n",
    "    # extract correlations strictly with time index\n",
    "    trend_by_window = trend_by_window.xs('idx_window_by_id', level=1)\n",
    "\n",
    "    vars_drop = (\n",
    "        [x for x in trend_by_window.columns if 'time_norm' in x]\n",
    "        + [x for x in trend_by_window.columns if 'frac_total' in x]\n",
    "        + ['idx_window_by_id']\n",
    "        )\n",
    "    trend_by_window = trend_by_window.drop(columns=vars_drop)\n",
    "\n",
    "    trend_by_window.columns = [\n",
    "        x + \"_ttrend\"\n",
    "        for x in trend_by_window.columns\n",
    "        ]\n",
    "\n",
    "    trend_by_window = trend_by_window.fillna(0)\n",
    "\n",
    "\n",
    "    vari_by_window = pd.merge(\n",
    "        entropy_by_window,\n",
    "        sd_by_window,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )   \n",
    "\n",
    "    vari_by_window = pd.merge(\n",
    "        vari_by_window,\n",
    "        trend_by_window,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )     \n",
    "    \n",
    "    \n",
    "    return vari_by_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_pipeline(X_logs, is_training_run):\n",
    "\n",
    "    X_logs_enriched = enrich_logs(X_logs, is_training_run)\n",
    "\n",
    "    aggregates_over_time = aggregate_no_time_dependence_measures(X_logs_enriched)\n",
    "    vari_by_window = aggregate_time_variability_measures(\n",
    "        aggregates_over_time, X_logs_enriched\n",
    "        )\n",
    "\n",
    "    X_transform = pd.merge(\n",
    "        aggregates_over_time,\n",
    "        vari_by_window,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )\n",
    "    \n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect train_logs are too large for single batch processing\n",
    "X_train_logs = extract(PATH_TRAIN_LOGS)\n",
    "\n",
    "X_train_logs_groups = [x for _, x in X_train_logs.groupby('id')]\n",
    "del X_train_logs\n",
    "\n",
    "X_train_logs_chunk1 = X_train_logs_groups[0:1200]\n",
    "X_train_logs_chunk2 = X_train_logs_groups[1200:]\n",
    "del X_train_logs_groups\n",
    "\n",
    "X_train_logs_chunk1 = pd.concat(X_train_logs_chunk1, axis=0)\n",
    "X_train_logs_chunk2 = pd.concat(X_train_logs_chunk2, axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chunk1 = feature_transform_pipeline(X_train_logs_chunk1, True)\n",
    "del X_train_logs_chunk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chunk2 = feature_transform_pipeline(X_train_logs_chunk2, True)\n",
    "del X_train_logs_chunk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_chunk1, X_train_chunk2], axis=0)\n",
    "del X_train_chunk1, X_train_chunk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"./data/processed/X_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     X_train\n",
    "#     .loc[X_train['id'].isin(['b732c6e2', 'b73648cf'])]\n",
    "#     .to_csv(\"./data/X_train_enriched_cases.csv\", index=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_pickle(\"./data/processed/train_logs_enriched.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     X_train\n",
    "#     .loc[X_train['id'].isin(['b73648cf'])]\n",
    "#     .to_csv(\"./data/X_train_enriched_case.csv\", index=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logs = extract(PATH_TRAIN_LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logs_sub = X_train_logs.loc[X_train_logs['id'] == '001519c8'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>1</td>\n",
       "      <td>4526</td>\n",
       "      <td>4557</td>\n",
       "      <td>31</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2</td>\n",
       "      <td>4558</td>\n",
       "      <td>4962</td>\n",
       "      <td>404</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>3</td>\n",
       "      <td>106571</td>\n",
       "      <td>106571</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Shift</td>\n",
       "      <td>Shift</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>4</td>\n",
       "      <td>106686</td>\n",
       "      <td>106777</td>\n",
       "      <td>91</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>5</td>\n",
       "      <td>107196</td>\n",
       "      <td>107323</td>\n",
       "      <td>127</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2553</td>\n",
       "      <td>1781786</td>\n",
       "      <td>1781841</td>\n",
       "      <td>55</td>\n",
       "      <td>Remove/Cut</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>q</td>\n",
       "      <td>555</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2554</td>\n",
       "      <td>1781917</td>\n",
       "      <td>1781991</td>\n",
       "      <td>74</td>\n",
       "      <td>Remove/Cut</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>q</td>\n",
       "      <td>554</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2555</td>\n",
       "      <td>1782062</td>\n",
       "      <td>1782141</td>\n",
       "      <td>79</td>\n",
       "      <td>Remove/Cut</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>q</td>\n",
       "      <td>553</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2556</td>\n",
       "      <td>1782922</td>\n",
       "      <td>1782985</td>\n",
       "      <td>63</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>554</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2557</td>\n",
       "      <td>1801877</td>\n",
       "      <td>1801969</td>\n",
       "      <td>92</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>1046</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2557 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  event_id  down_time  up_time  action_time       activity  \\\n",
       "0     001519c8         1       4526     4557           31  Nonproduction   \n",
       "1     001519c8         2       4558     4962          404  Nonproduction   \n",
       "2     001519c8         3     106571   106571            0  Nonproduction   \n",
       "3     001519c8         4     106686   106777           91          Input   \n",
       "4     001519c8         5     107196   107323          127          Input   \n",
       "...        ...       ...        ...      ...          ...            ...   \n",
       "2552  001519c8      2553    1781786  1781841           55     Remove/Cut   \n",
       "2553  001519c8      2554    1781917  1781991           74     Remove/Cut   \n",
       "2554  001519c8      2555    1782062  1782141           79     Remove/Cut   \n",
       "2555  001519c8      2556    1782922  1782985           63          Input   \n",
       "2556  001519c8      2557    1801877  1801969           92  Nonproduction   \n",
       "\n",
       "     down_event   up_event text_change  cursor_position  word_count  \n",
       "0     Leftclick  Leftclick    NoChange                0           0  \n",
       "1     Leftclick  Leftclick    NoChange                0           0  \n",
       "2         Shift      Shift    NoChange                0           0  \n",
       "3             q          q           q                1           1  \n",
       "4             q          q           q                2           1  \n",
       "...         ...        ...         ...              ...         ...  \n",
       "2552  Backspace  Backspace           q              555         255  \n",
       "2553  Backspace  Backspace           q              554         255  \n",
       "2554  Backspace  Backspace           q              553         255  \n",
       "2555          q          q           q              554         255  \n",
       "2556  Leftclick  Leftclick    NoChange             1046         255  \n",
       "\n",
       "[2557 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_logs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEssays(df):\n",
    "    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n",
    "    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n",
    "    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n",
    "    lastIndex = 0\n",
    "    essaySeries = pd.Series()\n",
    "    for index, valCount in enumerate(valCountsArr):\n",
    "        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n",
    "        lastIndex += valCount\n",
    "        essayText = \"\"\n",
    "        for Input in currTextInput.values:\n",
    "            if Input[0] == 'Replace':\n",
    "                replaceTxt = Input[2].split(' => ')\n",
    "                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] +\\\n",
    "                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "                continue\n",
    "            if Input[0] == 'Paste':\n",
    "                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "                continue\n",
    "            if Input[0] == 'Remove/Cut':\n",
    "                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "                continue\n",
    "            if \"M\" in Input[0]:\n",
    "                croppedTxt = Input[0][10:]\n",
    "                splitTxt = croppedTxt.split(' To ')\n",
    "                valueArr = [item.split(', ') for item in splitTxt]\n",
    "                moveData = (int(valueArr[0][0][1:]), \n",
    "                            int(valueArr[0][1][:-1]), \n",
    "                            int(valueArr[1][0][1:]), \n",
    "                            int(valueArr[1][1][:-1]))\n",
    "                if moveData[0] != moveData[2]:\n",
    "                    if moveData[0] < moveData[2]:\n",
    "                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n",
    "                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                    else:\n",
    "                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n",
    "                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                continue\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "        essaySeries[index] = essayText\n",
    "    essaySeries.index =  textInputDf['id'].unique()\n",
    "    return pd.DataFrame(essaySeries, columns=['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2363574567.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    continue\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def concatenate_essays(df):\n",
    "    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n",
    "    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n",
    "    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n",
    "    lastIndex = 0\n",
    "    essaySeries = pd.Series()\n",
    "    for index, valCount in enumerate(valCountsArr):\n",
    "        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n",
    "        lastIndex += valCount\n",
    "        essayText = \"\"\n",
    "        for Input in currTextInput.values:\n",
    "\n",
    "            cursor_position_after_event = Input[1]\n",
    "\n",
    "\n",
    "            if Input[0] == 'Replace':\n",
    "\n",
    "                replaceTxt = Input[2].split(' => ')\n",
    "                text_add = replaceTxt[1]\n",
    "                text_remove = replaceTxt[0]\n",
    "                cursor_position_start_text_change = (\n",
    "                    cursor_position_after_event - len(text_add)\n",
    "                    )\n",
    "                cursor_position_after_skip_replace = (\n",
    "                    cursor_position_start_text_change + len(text_remove)\n",
    "                )\n",
    "\n",
    "                # essayText start: \"the blue cat\"\n",
    "                # replace \"blue\" with \"red\"\n",
    "                # \"the redblue cat\", skip blue\n",
    "                essayText = (\n",
    "                    essayText[:cursor_position_start_text_change] # \"the \"\n",
    "                    + text_add # \"red\"\n",
    "                    # essayText value: \"the blue cat\" \n",
    "                    # want remaining \" cat\", NOT \"blue cat\"\n",
    "                    + essayText[cursor_position_after_skip_replace:] \n",
    "                    )\n",
    "\n",
    "                continue\n",
    "\n",
    "            if Input[0] == 'Paste':\n",
    "\n",
    "                text_change_event = Input[2]\n",
    "                cursor_position_start_text_change = (\n",
    "                    cursor_position_after_event - len(text_change_event)\n",
    "                    )\n",
    "\n",
    "                # essayText start: \"the cat\"\n",
    "                # paste \"blue \" between\n",
    "                essayText = (\n",
    "                    essayText[:cursor_position_start_text_change] # \"the \" \n",
    "                    + text_change_event # \"blue \"\n",
    "                    # essayText value: \"the cat\"\n",
    "                    + essayText[cursor_position_start_text_change:]\n",
    "                )\n",
    "\n",
    "                continue\n",
    "\n",
    "            if Input[0] == 'Remove/Cut':\n",
    "                # similar process to \"Replace\" action\n",
    "\n",
    "                text_remove = Input[2]\n",
    "                cursor_position_after_skip_remove = (\n",
    "                    cursor_position_after_event + len(text_remove)\n",
    "                )\n",
    "\n",
    "                essayText = (\n",
    "                    essayText[:cursor_position_after_event] \n",
    "                    + essayText[cursor_position_after_skip_remove:]\n",
    "                    )\n",
    "\n",
    "                continue\n",
    "            \n",
    "            if \"Move\" in Input[0]:\n",
    "\n",
    "                location_vectors_raw_str = (\n",
    "                    Input[0][10:]\n",
    "                    .replace(\"[\", \"\")\n",
    "                    .replace(\"]\", \"\")\n",
    "                    )\n",
    "                location_vectors = location_vectors_raw_str.split(' To ')\n",
    "                location_vector_from = \n",
    "                valueArr = [item.split(', ') for item in splitTxt]\n",
    "                moveData = (\n",
    "                    int(valueArr[0][0][1:]), \n",
    "                    int(valueArr[0][1][:-1]), \n",
    "                    int(valueArr[1][0][1:]), \n",
    "                    int(valueArr[1][1][:-1])\n",
    "                    )\n",
    "                if moveData[0] != moveData[2]:\n",
    "                    if moveData[0] < moveData[2]:\n",
    "                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n",
    "                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                    else:\n",
    "                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n",
    "                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                        \n",
    "                continue\n",
    "            \n",
    "\n",
    "            text_change_event = Input[2]\n",
    "            cursor_position_start_text_change = (\n",
    "                cursor_position_after_event - len(text_change_event)\n",
    "                )\n",
    "            essayText = (\n",
    "                essayText[:cursor_position_start_text_change] \n",
    "                + text_change_event\n",
    "                + essayText[cursor_position_start_text_change:]\n",
    "                )\n",
    "        \n",
    "        essaySeries[index] = essayText\n",
    "    essaySeries.index =  textInputDf['id'].unique()\n",
    "    return pd.DataFrame(essaySeries, columns=['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = \"Move From [284, 292] To [282, 290]\"\n",
    "location_vectors_raw_str = (\n",
    "    activity[10:]\n",
    "    .replace(\"[\", \"\")\n",
    "    .replace(\"]\", \"\")\n",
    "    )\n",
    "location_vectors = location_vectors_raw_str.split(' To ')\n",
    "valueArr = [item.split(', ') for item in splitTxt]\n",
    "# moveData = (\n",
    "#     int(valueArr[0][0][1:]), \n",
    "#     int(valueArr[0][1][:-1]), \n",
    "#     int(valueArr[1][0][1:]), \n",
    "#     int(valueArr[1][1][:-1])\n",
    "#     )\n",
    "# moveData = (\n",
    "#     int(valueArr[0][0][1:]), \n",
    "#     int(valueArr[0][1][:-1]), \n",
    "#     int(valueArr[1][0][1:]), \n",
    "#     int(valueArr[1][1][:-1])\n",
    "#     )\n",
    "# moveData = valueArr[0] + valueArr[1]\n",
    "# moveData = [int(x) for x in moveData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('284, 292 To 282, 290', ['284, 292', '282, 290'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_vectors_raw_str, location_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qqq q\n",
    "|T|h|e| |c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq qqqq qqqqqq qq qq qqqqq qq qqqq qqqqq qq qqqqqqqqq qqqqq qqqq qqqqq qqq qqqqqqqqq qqqqqqqqq qqqq.  qqqqqq qqq qqqqq qqq qqqqqqqqqqq qq qqq qqqqqqqqqq qqqqq, qqq qqqqq qqqqqq qq qq qqqq qqq qqqqqq qqqqqqq qq qqq qqqqqqqqqqq.  qqqqqqqq qq qqqqqqqqqq qqqq qqqq qqqqqqqqq qqq qqqqqqq qq qqqqqq qqqq qqq qqq qq qqqqqqqqq qq qq qqq qqqqq qqqqq qq qqq.\n",
      "\n",
      "qq qq qqqq qqqq qqq qqqqqqqqq qqq qqqqqqq qq qqq qqqqq qqqqq, qq qq qqqqqq qqq qqq qqqqqqqq qqqqq qq qqq qqqqqqqqqqq qq qqqqqqqqq.  qqqqqqqqq qq qqq qqqqqqqq qqqq qq qqqq qq qqqqqqq qqqqq qqqqq, qqq qqqqqq qqqqq qqqqq qqq qqq qq qqq qqqqqqq qqqqqqq qqqq.  qqqq qqqqq qqqqq qqqq qqqq'qq qqqqq qqqqqqqqq qqqqq qqqqqqq qqqqqqq qqqqqqqqqq, qqqq qq qqqqqqqqqq qqqqqqq qqq qqqqqqq; qqqqqqq, qqqqq qqqqqqqq qqqqqq qqqqqqq qqqqqqq qqq qqqqq qqq qqq qqq qqqqqqq.  qqqq qqqqqqqqq qqqq qqq qqqq qqqq qqqqq qqqqqqqqqq qqqq qqqqq qqqqq.  qqq qqqqqqqqqq qq qqqqqqqq q qqqqqq, qqqqqqqq qqqq qqqq qqqqqqqqqq, qqq. qq qqqqq qq qqqqq qqqqqqq qqqqqqqqq qq qq qqqq qqqqqqq. \n",
      "\n",
      "qqqq qqq qqqqqq qqqqqqqqqq qqqqqqqqq qqqqq, qqqqqq qqqqq qqq qqqqqq qqqq qq qqqqqq qqqqqqq qqqqq qqq qqqqqqqqq qqqq qqq qqqqq qq qqq.  qq qqqqq qqqqqqq qqq qqqqq qq qqqqqq qqq qqqqqq qqqqq qqq qqqqq qq qqqqqqqq qqqqqqqq qq qqqqqqqqq qqqq qq qqqq qq qqqqqq.  qqqqqqqq qq qqq qqqqqqqqqqq qq qqqqqqqq, qqq qqqqqqq qqqqqqqqq qqqqqq qq qqqqqq, qqqq qqqqq qq qq qqqqqq qq qqqq qqqq qqqqqqqqq.  qq qq qqq qqqqqqqqq qqqq qqq qq qqqqqq qqqqqqqq qq qqqqqqqq qq qqq qqq qqqqqqqq qqqqqqqqq.  \n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "text = getEssays(X_train_logs_sub).iat[0, 0]\n",
    "text_wrapped = textwrap.wrap(text) \n",
    "print( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001519c8' 1 4526 4557 31 'Nonproduction' 'Leftclick' 'Leftclick'\n",
      " 'NoChange' 0 0]\n",
      "['001519c8' 2 4558 4962 404 'Nonproduction' 'Leftclick' 'Leftclick'\n",
      " 'NoChange' 0 0]\n"
     ]
    }
   ],
   "source": [
    "for x in X_train_logs_sub.iloc[:2, ].values:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>text_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Replace</td>\n",
       "      <td>161</td>\n",
       "      <td>qqq qqqqq  =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Replace</td>\n",
       "      <td>178</td>\n",
       "      <td>qqqqq qq =&gt; q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Replace</td>\n",
       "      <td>235</td>\n",
       "      <td>qqqq  =&gt; q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>Replace</td>\n",
       "      <td>283</td>\n",
       "      <td>qqqqqqq qqqqqq  =&gt; q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>Replace</td>\n",
       "      <td>1298</td>\n",
       "      <td>qq qqqqqqqq qqqqq =&gt; q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>Replace</td>\n",
       "      <td>1301</td>\n",
       "      <td>qqqqq  =&gt; q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>Replace</td>\n",
       "      <td>1448</td>\n",
       "      <td>qqqqqqqqq  =&gt; q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     activity  cursor_position             text_change\n",
       "462   Replace              161         qqq qqqqq  =>  \n",
       "468   Replace              178           qqqqq qq => q\n",
       "512   Replace              235              qqqq  => q\n",
       "2364  Replace              283    qqqqqqq qqqqqq  => q\n",
       "2454  Replace             1298  qq qqqqqqqq qqqqq => q\n",
       "2474  Replace             1301             qqqqq  => q\n",
       "2481  Replace             1448         qqqqqqqqq  => q"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_logs_sub[['activity', 'cursor_position', 'text_change']].query(\"activity == 'Replace'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logs_sub.to_csv(\"./data/essay_reconstruct_case.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>2241</td>\n",
       "      <td>1017354</td>\n",
       "      <td>1017425</td>\n",
       "      <td>71</td>\n",
       "      <td>Paste</td>\n",
       "      <td>Space</td>\n",
       "      <td>Space</td>\n",
       "      <td>\\n</td>\n",
       "      <td>696</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>219</td>\n",
       "      <td>285459</td>\n",
       "      <td>285619</td>\n",
       "      <td>160</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqqqqqqq</td>\n",
       "      <td>95</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41276</th>\n",
       "      <td>00fc9a6a</td>\n",
       "      <td>1601</td>\n",
       "      <td>737215</td>\n",
       "      <td>737552</td>\n",
       "      <td>337</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqq qqqqqqq qqqqqq qqq qq qqqqqqqqqq qqq qq...</td>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41987</th>\n",
       "      <td>00fc9a6a</td>\n",
       "      <td>2312</td>\n",
       "      <td>1129516</td>\n",
       "      <td>1129835</td>\n",
       "      <td>319</td>\n",
       "      <td>Paste</td>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>qq qqqqqq qqqq,</td>\n",
       "      <td>980</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46948</th>\n",
       "      <td>014e7ae9</td>\n",
       "      <td>2455</td>\n",
       "      <td>828133</td>\n",
       "      <td>828256</td>\n",
       "      <td>123</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqq qqqqqq qqq qqqq qqqqqqqqqqq qq qqq qqqqq q...</td>\n",
       "      <td>1601</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372799</th>\n",
       "      <td>ff635a91</td>\n",
       "      <td>309</td>\n",
       "      <td>135266</td>\n",
       "      <td>135398</td>\n",
       "      <td>132</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqqqqq qqqqqqq qqq qqqqqqqqq qqqq</td>\n",
       "      <td>278</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374400</th>\n",
       "      <td>ff635a91</td>\n",
       "      <td>1910</td>\n",
       "      <td>1014489</td>\n",
       "      <td>1014642</td>\n",
       "      <td>153</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqqqqqqq</td>\n",
       "      <td>1443</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374465</th>\n",
       "      <td>ff635a91</td>\n",
       "      <td>1975</td>\n",
       "      <td>1031024</td>\n",
       "      <td>1031142</td>\n",
       "      <td>118</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqqqqqqq</td>\n",
       "      <td>1490</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374710</th>\n",
       "      <td>ff635a91</td>\n",
       "      <td>2220</td>\n",
       "      <td>1335273</td>\n",
       "      <td>1335382</td>\n",
       "      <td>109</td>\n",
       "      <td>Paste</td>\n",
       "      <td>Space</td>\n",
       "      <td>Space</td>\n",
       "      <td>qqqqqqqqqqq</td>\n",
       "      <td>660</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8402913</th>\n",
       "      <td>fff05981</td>\n",
       "      <td>635</td>\n",
       "      <td>441084</td>\n",
       "      <td>441172</td>\n",
       "      <td>88</td>\n",
       "      <td>Paste</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>qqqqqqq</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  event_id  down_time  up_time  action_time activity  \\\n",
       "4797     0022f953      2241    1017354  1017425           71    Paste   \n",
       "9365     0059420b       219     285459   285619          160    Paste   \n",
       "41276    00fc9a6a      1601     737215   737552          337    Paste   \n",
       "41987    00fc9a6a      2312    1129516  1129835          319    Paste   \n",
       "46948    014e7ae9      2455     828133   828256          123    Paste   \n",
       "...           ...       ...        ...      ...          ...      ...   \n",
       "8372799  ff635a91       309     135266   135398          132    Paste   \n",
       "8374400  ff635a91      1910    1014489  1014642          153    Paste   \n",
       "8374465  ff635a91      1975    1031024  1031142          118    Paste   \n",
       "8374710  ff635a91      2220    1335273  1335382          109    Paste   \n",
       "8402913  fff05981       635     441084   441172           88    Paste   \n",
       "\n",
       "        down_event up_event  \\\n",
       "4797         Space    Space   \n",
       "9365             v        v   \n",
       "41276            v        v   \n",
       "41987            z        z   \n",
       "46948            v        v   \n",
       "...            ...      ...   \n",
       "8372799          v        v   \n",
       "8374400          v        v   \n",
       "8374465          v        v   \n",
       "8374710      Space    Space   \n",
       "8402913          v        v   \n",
       "\n",
       "                                               text_change  cursor_position  \\\n",
       "4797                                                   \\n               696   \n",
       "9365                                          qqqqqqqqqqq                95   \n",
       "41276    qqqqqq qqqqqqq qqqqqq qqq qq qqqqqqqqqq qqq qq...               78   \n",
       "41987                                      qq qqqqqq qqqq,              980   \n",
       "46948    qqq qqqqqq qqq qqqq qqqqqqqqqqq qq qqq qqqqq q...             1601   \n",
       "...                                                    ...              ...   \n",
       "8372799               qqqqqqqqq qqqqqqq qqq qqqqqqqqq qqqq              278   \n",
       "8374400                                        qqqqqqqqqqq             1443   \n",
       "8374465                                        qqqqqqqqqqq             1490   \n",
       "8374710                                        qqqqqqqqqqq              660   \n",
       "8402913                                            qqqqqqq               15   \n",
       "\n",
       "         word_count  \n",
       "4797            316  \n",
       "9365             23  \n",
       "41276           153  \n",
       "41987           230  \n",
       "46948           280  \n",
       "...             ...  \n",
       "8372799          44  \n",
       "8374400         248  \n",
       "8374465         255  \n",
       "8374710         287  \n",
       "8402913          29  \n",
       "\n",
       "[599 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_logs.query(\"activity=='Paste'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2360</td>\n",
       "      <td>1380334</td>\n",
       "      <td>1380334</td>\n",
       "      <td>0</td>\n",
       "      <td>Move From [284, 292] To [282, 290]</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>qqqqqqq</td>\n",
       "      <td>290</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2363</td>\n",
       "      <td>1382896</td>\n",
       "      <td>1382896</td>\n",
       "      <td>0</td>\n",
       "      <td>Move From [287, 289] To [285, 287]</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>qq</td>\n",
       "      <td>287</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2516</td>\n",
       "      <td>1735021</td>\n",
       "      <td>1735021</td>\n",
       "      <td>0</td>\n",
       "      <td>Move From [460, 461] To [465, 466]</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>q</td>\n",
       "      <td>466</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263545</th>\n",
       "      <td>07bb2245</td>\n",
       "      <td>2374</td>\n",
       "      <td>1282273</td>\n",
       "      <td>1282273</td>\n",
       "      <td>0</td>\n",
       "      <td>Move From [905, 1314] To [907, 1316]</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>qqqqq qqqq qqqqqqq qqqq qqqq qqqqqq qqqqqqqq ...</td>\n",
       "      <td>1316</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263572</th>\n",
       "      <td>07bb2245</td>\n",
       "      <td>2401</td>\n",
       "      <td>1650084</td>\n",
       "      <td>1650084</td>\n",
       "      <td>0</td>\n",
       "      <td>Move From [565, 743] To [669, 847]</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>qqqq qqqqqq q qqqq qq qqqqq qqqq qqqq qqqqqqq....</td>\n",
       "      <td>847</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  event_id  down_time  up_time  action_time  \\\n",
       "2359    001519c8      2360    1380334  1380334            0   \n",
       "2362    001519c8      2363    1382896  1382896            0   \n",
       "2515    001519c8      2516    1735021  1735021            0   \n",
       "263545  07bb2245      2374    1282273  1282273            0   \n",
       "263572  07bb2245      2401    1650084  1650084            0   \n",
       "\n",
       "                                    activity down_event   up_event  \\\n",
       "2359      Move From [284, 292] To [282, 290]  Leftclick  Leftclick   \n",
       "2362      Move From [287, 289] To [285, 287]  Leftclick  Leftclick   \n",
       "2515      Move From [460, 461] To [465, 466]  Leftclick  Leftclick   \n",
       "263545  Move From [905, 1314] To [907, 1316]  Leftclick  Leftclick   \n",
       "263572    Move From [565, 743] To [669, 847]  Leftclick  Leftclick   \n",
       "\n",
       "                                              text_change  cursor_position  \\\n",
       "2359                                             qqqqqqq               290   \n",
       "2362                                                   qq              287   \n",
       "2515                                                    q              466   \n",
       "263545   qqqqq qqqq qqqqqqq qqqq qqqq qqqqqq qqqqqqqq ...             1316   \n",
       "263572  qqqq qqqqqq q qqqq qq qqqqq qqqq qqqq qqqqqqq....              847   \n",
       "\n",
       "        word_count  \n",
       "2359           244  \n",
       "2362           244  \n",
       "2515           256  \n",
       "263545         275  \n",
       "263572         275  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_logs.loc[X_train_logs['activity'].str.contains('Move')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
