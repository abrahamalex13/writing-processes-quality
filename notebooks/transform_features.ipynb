{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import plotnine as p9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/external/train_logs.csv\")\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .sort_values([\"id\", \"event_id\"], ascending=[True, True])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = X_train.loc[(\n",
    "    (X_train['activity'] == 'Input')\n",
    "    & (~ X_train['text_change'].isin(['q', ' ']))\n",
    "    ), 'text_change'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Move From' activity recorded with low-level cursor loc details\n",
    "# extract bigger-picture 'Move From'\n",
    "# QUESTION: what's the difference between Move From, and a cut+paste?\n",
    "X_train['activity_detailed'] = X_train['activity']\n",
    "X_train.loc[X_train['activity'].str.contains('Move From'), 'activity'] = 'Move'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no explicit record for a pause. pauses are omitted.\n",
    "PAUSE_THRESHOLD_MS = 1000\n",
    "\n",
    "X_train['up_time_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['up_time']\n",
    "    .shift(1)\n",
    "    )\n",
    "# latency does not mean a meaningful pause\n",
    "X_train['latency_time'] = (\n",
    "    X_train['down_time'] - X_train['up_time_lag1']\n",
    "    )\n",
    "X_train['preceding_pause_time'] = X_train['latency_time']\n",
    "# expect some negative pause times -- interpret as, no real pause\n",
    "has_no_real_pause = X_train['preceding_pause_time'] <= PAUSE_THRESHOLD_MS\n",
    "X_train.loc[has_no_real_pause, 'preceding_pause_time'] = None\n",
    "# not obvious how to tag \"initial planning pause\" \n",
    "X_train['preceding_pause_time_start_window'] = X_train['preceding_pause_time']\n",
    "X_train.loc[X_train['up_time'] > 5 * 60 * 1000, 'preceding_pause_time_start_window'] = None\n",
    "\n",
    "X_train['total_pause_time'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['preceding_pause_time']\n",
    "    .transform('sum')\n",
    "    )\n",
    "X_train['rolling_pause_time'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['preceding_pause_time']\n",
    "    .cumsum()\n",
    "    )\n",
    "X_train['rolling_pause_time_fraction'] = (\n",
    "    X_train['rolling_pause_time'] / X_train['total_pause_time']\n",
    "    )\n",
    "\n",
    "# summarize pause distr\n",
    "MS_IN_PAUSE_BUCKET_MAX = 200e3\n",
    "PAUSE_BUCKET_STEP_MS = 500\n",
    "\n",
    "X_train['preceding_pause_time_bucket'] = pd.cut(\n",
    "    X_train['preceding_pause_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        MS_IN_PAUSE_BUCKET_MAX,\n",
    "        PAUSE_BUCKET_STEP_MS\n",
    "        )\n",
    "    )\n",
    "\n",
    "X_train['preceding_pause_time_bucket'].value_counts()\n",
    "\n",
    "# WARNING: this representation of pause distribution is dense & large\n",
    "# a few parameters from distribution model far more succinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pause exceeds threshold duration, a \"burst\" has ended\n",
    "MS_PER_S = 1000\n",
    "SECONDS_PER_BURST = 2\n",
    "\n",
    "X_train['is_new_burst_start'] = (\n",
    "    X_train['preceding_pause_time'] > MS_PER_S * SECONDS_PER_BURST\n",
    "    ).astype(int)\n",
    "X_train['is_new_burst_start'][0] = 1\n",
    "X_train['burst_id'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['is_new_burst_start']\n",
    "    .cumsum()\n",
    "    )\n",
    "X_train['burst_time_start'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['down_time']\n",
    "    .transform('min')\n",
    "    )\n",
    "X_train['burst_time_end'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['up_time']\n",
    "    .transform('max')\n",
    "    )\n",
    "X_train['burst_duration'] = X_train['burst_time_end'] - X_train['burst_time_start']\n",
    "\n",
    "X_train['burst_duration_x_is_new_burst_start'] = (\n",
    "    X_train['burst_duration']\n",
    "    * X_train['is_new_burst_start']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-way cursor movement might be most productive\n",
    "# jumping around is choppy\n",
    "X_train['cursor_position_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position']\n",
    "    .shift(1)\n",
    "    )\n",
    "\n",
    "X_train['has_cursor_position_moved_right'] = (\n",
    "    X_train['cursor_position'] > X_train['cursor_position_lag1']\n",
    "    ).astype(int)\n",
    "\n",
    "# farthest position cursor has _edited_, with recorded input\n",
    "X_train['cursor_position_cummax'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position']\n",
    "    .cummax()\n",
    "    )\n",
    "X_train.loc[X_train['activity'] != 'Input', 'cursor_position_cummax'] = None\n",
    "X_train['cursor_position_cummax'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['cursor_position_cummax']\n",
    "    .ffill()\n",
    "    )\n",
    "\n",
    "X_train['cursor_position_vs_max'] = (\n",
    "    X_train['cursor_position'] - X_train['cursor_position_cummax']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count offers a productivity measure\n",
    "X_train['word_count_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['word_count']\n",
    "    .shift(1)\n",
    "    )\n",
    "\n",
    "X_train['word_count_delta_event'] = (\n",
    "    X_train['word_count'] - X_train['word_count_lag1']\n",
    "    )\n",
    "\n",
    "X_train['word_count_delta_burst'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['word_count_delta_event']\n",
    "    .transform('sum')\n",
    "    )\n",
    "\n",
    "# word length offers a content quality measure.\n",
    "# hard to track entire words sequence in rolling fashion.\n",
    "    # every word's length, in a list of one element per word?  \n",
    "# more tractable to track very latest string\n",
    "\n",
    "is_edit_to_latest_string = X_train['cursor_position_vs_max'] == 0\n",
    "\n",
    "X_train['is_new_latest_string_start'] = (\n",
    "    is_edit_to_latest_string\n",
    "    & (X_train['activity'] == \"Input\")\n",
    "    & (X_train[\"text_change\"] == ' ')\n",
    "    )\n",
    "\n",
    "X_train['is_latest_string_end'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['is_new_latest_string_start']\n",
    "    .shift(-1)\n",
    "    # last process records\n",
    "    .fillna(True)\n",
    "    )\n",
    "\n",
    "X_train['n_alphanum_char_added_to_latest_string'] = 0\n",
    "is_alphanumeric_addition = (\n",
    "    (X_train['activity'] == \"Input\")\n",
    "    & (X_train[\"text_change\"] == 'q')\n",
    "    )\n",
    "X_train.loc[\n",
    "    (is_alphanumeric_addition & is_edit_to_latest_string), \n",
    "    'n_alphanum_char_added_to_latest_string'\n",
    "    ] = 1\n",
    "is_alphanumeric_subtraction = (\n",
    "    (X_train['activity'] == \"Remove/Cut\")\n",
    "    & (X_train['up_event'] == 'Backspace')\n",
    "    & (X_train[\"text_change\"] == 'q')\n",
    "    )\n",
    "X_train.loc[\n",
    "    (is_alphanumeric_subtraction & is_edit_to_latest_string), \n",
    "    'n_alphanum_char_added_to_latest_string'\n",
    "    ] = -1\n",
    "# example: 2nd string, 2 characters in.\n",
    "# considering cumsum for each character in 2nd string, \n",
    "# subtract those characters from 1st\n",
    "X_train['rolling_length_latest_string'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['n_alphanum_char_added_to_latest_string']\n",
    "    .cumsum() \n",
    "    ) - (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['n_alphanum_char_added_to_latest_string']\n",
    "    .cumsum()\n",
    "    .where(X_train['is_new_latest_string_start']) \n",
    "    .ffill()\n",
    "    .fillna(0)\n",
    "    )\n",
    "\n",
    "X_train['length_latest_string'] = None\n",
    "X_train.loc[X_train['is_latest_string_end'], 'length_latest_string'] = X_train['rolling_length_latest_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if thoughts aren't separated by punctuation, writing won't score well\n",
    "X_train['is_thought_delimiting_punctuation'] = (\n",
    "    (X_train['text_change'] == \".\")\n",
    "    | (X_train['text_change'] == \". \")\n",
    "    | (X_train['text_change'] == \",\")\n",
    "    | (X_train['text_change'] == \"-\")\n",
    "    | (X_train['text_change'] == \"!\")\n",
    "    | (X_train['text_change'] == \";\")\n",
    "    | (X_train['text_change'] == \"?\")\n",
    "    | (X_train['text_change'] == \":\")\n",
    "    ).astype(int)\n",
    "\n",
    "X_train['is_special_punctuation'] = (\n",
    "    (X_train['text_change'] == \"=\")\n",
    "    | (X_train['text_change'] == \"/\")\n",
    "    | (X_train['text_change'] == \"\\\\\")\n",
    "    | (X_train['text_change'] == \"(\")\n",
    "    | (X_train['text_change'] == \")\")\n",
    "    | (X_train['text_change'] == \"\\n\")\n",
    "    | (X_train['text_change'] == \"[\")\n",
    "    | (X_train['text_change'] == \"]\")\n",
    "    | (X_train['text_change'] == \">\")\n",
    "    | (X_train['text_change'] == \"<\")\n",
    "    | (X_train['text_change'] == \"$\")\n",
    "    | (X_train['text_change'] == \"*\")\n",
    "    | (X_train['text_change'] == \"&\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows allow for time-sequence features\n",
    "TOTAL_MIN = 30\n",
    "SECONDS_PER_MIN = 60\n",
    "SECONDS_PER_WINDOW = 30\n",
    "\n",
    "X_train['window_30s'] = pd.cut(\n",
    "    X_train['down_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        TOTAL_MIN * SECONDS_PER_MIN * MS_PER_S + 5*MS_PER_S*2, \n",
    "        SECONDS_PER_WINDOW * MS_PER_S\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CATEGORIES = ['Nonproduction', 'Input', 'Remove/Cut', 'Replace', 'Paste', 'Move']\n",
    "\n",
    "pipeline_activity_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ACTIVITY_CATEGORIES], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"activity\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_activity_onehot.fit(X_train)\n",
    "original_categorical = X_train['activity']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_activity_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_activity_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['burst_action_time_' + activity] = (\n",
    "        X_train\n",
    "        .assign(activity_x_event_time = lambda x: x['activity_' + activity] * x.action_time)\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['activity_x_event_time']\n",
    "        .transform('sum')\n",
    "        ).astype(float)\n",
    "    \n",
    "X_train['burst_type'] = (\n",
    "    X_train\n",
    "    [['burst_action_time_' + activity for activity in ACTIVITY_CATEGORIES]]\n",
    "    .idxmax(axis=1)\n",
    "    )\n",
    "X_train['burst_type'] = (\n",
    "    X_train['burst_type']\n",
    "    .str\n",
    "    .replace(\"burst_action_time_\", \"\", regex=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_burst_type_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ACTIVITY_CATEGORIES], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"burst_type\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_burst_type_onehot.fit(X_train)\n",
    "original_categorical = X_train['burst_type']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_burst_type_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_burst_type_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)\n",
    "\n",
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['is_new_burst_start_' + activity] = (\n",
    "        X_train['is_new_burst_start'] * \n",
    "        X_train['burst_type_' + activity]\n",
    "        )\n",
    "    \n",
    "    X_train['burst_duration_x_is_new_burst_start_' + activity] = (\n",
    "        X_train['burst_duration_x_is_new_burst_start'] * \n",
    "        X_train['burst_type_' + activity]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[\n",
    "    \"id\",\n",
    "    \"event_id\",\n",
    "    \"window_30s\",\n",
    "    \"burst_id\",\n",
    "    \"burst_type\",\n",
    "    \"burst_type_Nonproduction\",\n",
    "    \"burst_type_Input\",\n",
    "    \"burst_type_Remove/Cut\",\n",
    "    \"burst_type_Replace\",\n",
    "    \"burst_type_Paste\",\n",
    "    \"burst_type_Move\",\n",
    "    \"is_new_burst_start\",\n",
    "    \"is_new_burst_start_Nonproduction\",\n",
    "    \"is_new_burst_start_Input\",\n",
    "    \"is_new_burst_start_Remove/Cut\",\n",
    "    \"is_new_burst_start_Replace\",\n",
    "    \"is_new_burst_start_Paste\",\n",
    "    \"is_new_burst_start_Move\",\n",
    "    \"burst_time_start\",\n",
    "    \"burst_time_end\",\n",
    "    \"burst_duration\",\n",
    "    \"burst_duration_x_is_new_burst_start\",\n",
    "    \"burst_duration_x_is_new_burst_start_Nonproduction\",\n",
    "    \"burst_duration_x_is_new_burst_start_Input\",\n",
    "    \"burst_duration_x_is_new_burst_start_Remove/Cut\",\n",
    "    \"burst_duration_x_is_new_burst_start_Replace\",\n",
    "    \"burst_duration_x_is_new_burst_start_Paste\",\n",
    "    \"burst_duration_x_is_new_burst_start_Move\",\n",
    "    \"word_count_delta_burst\",\n",
    "\n",
    "    \"down_time\",\n",
    "    \"up_time\",\t\n",
    "    \"action_time\",\t\n",
    "    \"activity_detailed\",\n",
    "    \"activity\",\t\n",
    "    \"activity_Nonproduction\",\n",
    "    \"activity_Input\",\n",
    "    \"activity_Remove/Cut\",\n",
    "    \"activity_Replace\",\n",
    "    \"activity_Paste\",\n",
    "    \"activity_Move\",\n",
    "    \"down_event\",\t\n",
    "    \"up_event\",\t\n",
    "    \"text_change\",\n",
    "    \"is_thought_delimiting_punctuation\",\n",
    "    \"cursor_position\",\t\n",
    "    \"word_count\",\n",
    "\n",
    "    \"cursor_position_vs_max\",\n",
    "    \"cursor_position_cummax\",\n",
    "    \"has_cursor_position_moved_right\",\n",
    "\n",
    "    \"is_new_latest_string_start\",\n",
    "    \"is_latest_string_end\",\n",
    "    \"n_alphanum_char_added_to_latest_string\",\n",
    "    \"rolling_length_latest_string\",\n",
    "    \"length_latest_string\",\n",
    "\n",
    "    \"word_count_lag1\",\n",
    "    \"word_count_delta_event\",\n",
    "\n",
    "    \"up_time_lag1\",\n",
    "    \"latency_time\",\n",
    "    \"preceding_pause_time\",\n",
    "    \"preceding_pause_time_start_window\",\n",
    "    \"preceding_pause_time_bucket\",\n",
    "    \"rolling_pause_time\",\n",
    "    \"rolling_pause_time_fraction\",\n",
    "    \"total_pause_time\",\n",
    "\n",
    "    \"burst_action_time_Nonproduction\",\n",
    "    \"burst_action_time_Input\",\n",
    "    \"burst_action_time_Remove/Cut\",\n",
    "    \"burst_action_time_Replace\",\n",
    "    \"burst_action_time_Paste\",\n",
    "    \"burst_action_time_Move\"\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_vars_sum = (\n",
    "    ['activity_' + x for x in ACTIVITY_CATEGORIES] \n",
    "    + ['is_new_burst_start'] \n",
    "    + ['is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    + [\"is_thought_delimiting_punctuation\"]\n",
    "    )\n",
    "\n",
    "events_sum_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    [event_vars_sum]\n",
    "    .agg(sum)\n",
    "    )\n",
    "\n",
    "events_sum_over_time['delete_insert_ratio'] = (\n",
    "    events_sum_over_time['activity_Remove/Cut'] / \n",
    "    events_sum_over_time['activity_Input'] \n",
    "    )\n",
    "\n",
    "conti_vars_sum = (\n",
    "    ['word_count_delta_event']\n",
    "    + [\"preceding_pause_time\"]\n",
    "    + ['burst_duration_x_is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    )\n",
    "\n",
    "conti_sum_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    [conti_vars_sum]\n",
    "    .agg(sum)\n",
    "    )\n",
    "\n",
    "sums_over_time = pd.merge(\n",
    "    events_sum_over_time,\n",
    "    conti_sum_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrals_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        latency_time_p50 = ('latency_time', np.median),\n",
    "        pause_time_p50 = ('preceding_pause_time', np.median),\n",
    "        has_cursor_position_moved_right_mean = ('has_cursor_position_moved_right', 'mean'),\n",
    "        burst_duration_mean = ('burst_duration', 'mean'),\n",
    "        burst_duration_p50 = ('burst_duration', np.median),\n",
    "        word_count_delta_burst_p50 = ('word_count_delta_burst', np.median),\n",
    "        cursor_position_vs_max_avg = ('cursor_position_vs_max', 'mean'),\n",
    "        length_latest_string_mean = ('length_latest_string', 'mean'),\n",
    "        length_latest_string_stddev = ('length_latest_string', np.std)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_over_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        pause_time_max=('preceding_pause_time', 'max'),\n",
    "        initial_pause_time_max=('preceding_pause_time_start_window', 'max'),\n",
    "        # approximation to, next longest pause after first long planning pause\n",
    "        pause_time_p99=('preceding_pause_time', lambda x: x.quantile(0.99)),\n",
    "        burst_duration_max=('burst_duration', 'max'),\n",
    "        total_time=('up_time', 'max'),\n",
    "        length_latest_string_max=('length_latest_string', 'max'),\n",
    "        latency_time_min=('latency_time', 'min')\n",
    "        )\n",
    "    )\n",
    "\n",
    "extremes_over_time['is_initial_pause_max_pause'] = (\n",
    "    extremes_over_time['pause_time_max'] == \n",
    "    extremes_over_time['initial_pause_time_max']\n",
    "    ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm\n",
    "\n",
    "pause_distr_summary_subjects = []\n",
    "\n",
    "for X_train_subject in [x for _, x in X_train.groupby('id')]:\n",
    "\n",
    "    shape, location, scale = lognorm.fit(X_train_subject['preceding_pause_time'].dropna())\n",
    "\n",
    "    pause_distr_summary = pd.DataFrame({\n",
    "        'pauses_lognorm_shape': [shape], \n",
    "        'pauses_lognorm_location': [location],\n",
    "        'pauses_lognorm_scale': [scale]\n",
    "        })\n",
    "    pause_distr_summary.index = [X_train_subject['id'].iloc[0]]\n",
    "    \n",
    "    pause_distr_summary_subjects.append(pause_distr_summary)\n",
    "\n",
    "distr_params_over_time = pd.concat(pause_distr_summary_subjects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_over_time = pd.merge(\n",
    "    sums_over_time, \n",
    "    centrals_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "aggregates_over_time = pd.merge(\n",
    "    aggregates_over_time, \n",
    "    extremes_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "aggregates_over_time = pd.merge(\n",
    "    aggregates_over_time, \n",
    "    distr_params_over_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in event_vars_sum:\n",
    "\n",
    "    aggregates_over_time[var + '_per_s'] = (\n",
    "        1000 * (aggregates_over_time[var] / aggregates_over_time['total_time'])\n",
    "        )\n",
    "\n",
    "aggregates_over_time = (\n",
    "    aggregates_over_time\n",
    "    .assign(\n",
    "        keystroke_speed = lambda x: (x.activity_Input + x['activity_Remove/Cut']) / x.total_time,\n",
    "        words_per_thought_delimiting_punctuation = lambda x: x.word_count_delta_event / x.is_thought_delimiting_punctuation,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_over_time.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_by_window = (\n",
    "    X_train\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    [event_vars_sum]\n",
    "    .agg(sum)\n",
    "    .astype(float)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "events_by_window['window_30s_idx'] = events_by_window.index\n",
    "\n",
    "events_by_window['delete_insert_ratio'] = (\n",
    "    events_by_window['activity_Remove/Cut'] / \n",
    "    events_by_window['activity_Input'] \n",
    "    )\n",
    "\n",
    "# for variability measure more comparable between writers, de-mean by writer. \n",
    "# Ex: higher-throughput writer incurs higher stddev, because values have higher magnitude\n",
    "# join method allows for merge on one index column, of multiple possible\n",
    "events_by_window = events_by_window.join(\n",
    "    aggregates_over_time[[x + '_per_s' for x in event_vars_sum]],\n",
    "    on='id',\n",
    "    how='left'\n",
    "    )\n",
    "for var in event_vars_sum:\n",
    "    events_by_window[var + '_time_norm'] = (\n",
    "        events_by_window[var] / \n",
    "        (events_by_window[var + '_per_s'].replace(0, None) * 30)\n",
    "        )\n",
    "    events_by_window[var] = events_by_window[var].fillna(1)\n",
    "events_by_window = events_by_window.drop(columns=[x + '_per_s' for x in event_vars_sum])\n",
    "\n",
    "events_over_time_ren = aggregates_over_time[event_vars_sum]\n",
    "events_over_time_ren.columns = [x + \"_total\" for x in events_over_time_ren.columns]\n",
    "events_by_window = events_by_window.join(events_over_time_ren, on='id', how='left')\n",
    "for var in event_vars_sum:\n",
    "    events_by_window[var + '_frac_total'] = (\n",
    "        events_by_window[var] / events_by_window[var + 'total']\n",
    "        )\n",
    "events_by_window = events_by_window.drop(columns=[x + '_total' for x in event_vars_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conti_by_window = (\n",
    "    X_train\n",
    "    .assign()\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    [conti_vars_sum]\n",
    "    .agg(sum)\n",
    "    .astype(float)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "conti_by_window['window_30s_idx'] = conti_by_window.index\n",
    "\n",
    "conti_over_time_ren = aggregates_over_time[conti_vars_sum]\n",
    "conti_over_time_ren.columns = [x + \"_total\" for x in conti_over_time_ren.columns]\n",
    "conti_by_window = conti_by_window.join(conti_over_time_ren, on='id', how='left')\n",
    "for var in conti_vars_sum:\n",
    "    conti_by_window[var + '_frac_total'] = (\n",
    "        conti_by_window[var] / conti_by_window[var + 'total']\n",
    "        )\n",
    "conti_by_window = conti_by_window.drop(columns=[x + '_total' for x in event_vars_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrals_by_window = (\n",
    "    X_train\n",
    "    .assign()\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    ['cursor_position_vs_max']\n",
    "    .agg('mean')\n",
    "    .astype(float)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "centrals_by_window['window_30s_idx'] = centrals_by_window.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates_by_window = pd.merge(\n",
    "    events_by_window, \n",
    "    conti_by_window,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "aggregates_by_window = pd.merge(\n",
    "    events_by_window, \n",
    "    centrals_by_window,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "entropy_vars = [var for var in aggregates_by_window.columns if 'frac_total' in var]\n",
    "entropy_by_window = (\n",
    "    aggregates_by_window\n",
    "    [entropy_vars]\n",
    "    .groupby(['id'])\n",
    "    .agg(entropy)\n",
    "    )\n",
    "entropy_by_window.columns = [\n",
    "    x + '_entropy' \n",
    "    for x in entropy_by_window.columns\n",
    "    ]\n",
    "\n",
    "\n",
    "sd_by_window = (\n",
    "    aggregates_by_window\n",
    "    .drop(columns=['window_30s', 'window_30s_idx'])\n",
    "    .groupby(['id'])\n",
    "    .agg(np.std)\n",
    "    )\n",
    "sd_by_window.columns = [\n",
    "    x + \"_stddev\"\n",
    "    for x in sd_by_window.columns\n",
    "    ]\n",
    "\n",
    "\n",
    "trend_by_window = (\n",
    "    aggregates_by_window\n",
    "    .sort_values(['id', 'window_30s_idx'])\n",
    "    .agg(lambda x: np.cor(x.window_30s_idx, ))\n",
    "    .drop(columns=['window_30s', 'window_30s_idx'])\n",
    "    .groupby(['id'])\n",
    "    )\n",
    "\n",
    "trend_by_window.columns = [\n",
    "    x + \"_ttrend\"\n",
    "    for x in trend_by_window.columns\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = pd.merge(\n",
    "    X_train_marginals_wrt_time,\n",
    "    X_train_windows_variation,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURSOR_POSITION_VS_MAX_STDDEV_P50 = 246.6\n",
    "\n",
    "X_train_transform['cursor_position_vs_max_stddev'] = (\n",
    "    X_train_transform['cursor_position_vs_max_stddev'].fillna(CURSOR_POSITION_VS_MAX_STDDEV_P50)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_transform\n",
    "    .drop(columns='delete_insert_ratio_stddev')\n",
    "    .to_pickle(\"./data/processed/X_train.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
