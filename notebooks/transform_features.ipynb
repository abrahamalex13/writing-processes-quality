{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import plotnine as p9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/external/train_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no explicit record for a pause. pauses are omitted.\n",
    "X_train = (\n",
    "    X_train\n",
    "    .sort_values([\"id\", \"event_id\"], ascending=[True, True])\n",
    "    )\n",
    "\n",
    "X_train['up_time_lag1'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['up_time']\n",
    "    .shift(1)\n",
    "    )\n",
    "\n",
    "X_train['preceding_pause_time'] = (\n",
    "    X_train['down_time'] - X_train['up_time_lag1']\n",
    "    )\n",
    "# expect some negative pause times -- interpret as, no real pause\n",
    "has_no_real_pause = X_train['preceding_pause_time'] <= 0\n",
    "X_train.loc[has_no_real_pause, 'preceding_pause_time'] = None\n",
    "\n",
    "# if pause exceeds threshold duration, a \"burst\" has ended\n",
    "MS_PER_S = 1000\n",
    "SECONDS_PER_BURST = 2\n",
    "\n",
    "X_train['is_new_burst_start'] = (\n",
    "    X_train['preceding_pause_time'] > MS_PER_S * SECONDS_PER_BURST\n",
    "    ).astype(int)\n",
    "X_train['is_new_burst_start'][0] = 1\n",
    "X_train['burst_id'] = (\n",
    "    X_train\n",
    "    .groupby(['id'])\n",
    "    ['is_new_burst_start']\n",
    "    .cumsum()\n",
    "    )\n",
    "X_train['burst_time_start'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['down_time']\n",
    "    .transform('min')\n",
    "    )\n",
    "X_train['burst_time_end'] = (\n",
    "    X_train\n",
    "    .groupby(['id', 'burst_id'])\n",
    "    ['up_time']\n",
    "    .transform('max')\n",
    "    )\n",
    "X_train['burst_duration'] = X_train['burst_time_end'] - X_train['burst_time_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows allow for time-sequence features\n",
    "TOTAL_MIN = 30\n",
    "SECONDS_PER_MIN = 60\n",
    "SECONDS_PER_WINDOW = 30\n",
    "\n",
    "X_train['window_30s'] = pd.cut(\n",
    "    X_train['down_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        TOTAL_MIN * SECONDS_PER_MIN * MS_PER_S + 5*MS_PER_S*2, \n",
    "        SECONDS_PER_WINDOW * MS_PER_S\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize pause distr\n",
    "MS_IN_PAUSE_BUCKET_MAX = 200e3\n",
    "PAUSE_BUCKET_STEP_MS = 500\n",
    "\n",
    "X_train['preceding_pause_time_bucket'] = pd.cut(\n",
    "    X_train['preceding_pause_time'],\n",
    "    bins=np.arange(\n",
    "        0, \n",
    "        MS_IN_PAUSE_BUCKET_MAX,\n",
    "        PAUSE_BUCKET_STEP_MS\n",
    "        )\n",
    "    )\n",
    "\n",
    "X_train['preceding_pause_time_bucket'].value_counts()\n",
    "\n",
    "# WARNING: this representation of pause distribution is dense & large\n",
    "# a few parameters from distribution model far more succinct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CATEGORIES = ['Nonproduction', 'Input', 'Remove/Cut']\n",
    "\n",
    "pipeline_activity_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ ACTIVITY_CATEGORIES ], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"activity\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_activity_onehot.fit(X_train)\n",
    "original_categorical = X_train['activity']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_activity_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_activity_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['burst_action_time_' + activity] = (\n",
    "        X_train\n",
    "        .assign(activity_x_event_time = lambda x: x['activity_' + activity] * x.action_time)\n",
    "        .groupby(['id', 'burst_id'])\n",
    "        ['activity_x_event_time']\n",
    "        .transform('sum')\n",
    "        ).astype(float)\n",
    "    \n",
    "X_train['burst_type'] = (\n",
    "    X_train\n",
    "    [['burst_action_time_' + activity for activity in ACTIVITY_CATEGORIES]]\n",
    "    .idxmax(axis=1)\n",
    "    )\n",
    "X_train['burst_type'] = (\n",
    "    X_train['burst_type']\n",
    "    .str\n",
    "    .replace(\"burst_action_time_\", \"\", regex=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CATEGORIES = ['Nonproduction', 'Input', 'Remove/Cut']\n",
    "\n",
    "pipeline_burst_type_onehot = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        'onehot_encode', \n",
    "        preprocessing.OneHotEncoder(\n",
    "            categories=[ ACTIVITY_CATEGORIES ], \n",
    "            sparse=False, \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            ),\n",
    "        [\"burst_type\"]\n",
    "    )],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "    )\n",
    "pipeline_burst_type_onehot.fit(X_train)\n",
    "original_categorical = X_train['burst_type']\n",
    "\n",
    "X_train_dtypes = X_train.dtypes.to_dict()\n",
    "X_train = pipeline_burst_type_onehot.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=pipeline_burst_type_onehot.get_feature_names_out())\n",
    "X_train = pd.concat([X_train, original_categorical], axis=1)\n",
    "X_train = X_train.astype(X_train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activity in ACTIVITY_CATEGORIES:\n",
    "\n",
    "    X_train['is_new_burst_start_' + activity] = (\n",
    "        X_train['is_new_burst_start'] * \n",
    "        X_train['burst_type_' + activity]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[\n",
    "    \"id\",\n",
    "    \"event_id\",\n",
    "    \"window_30s\",\n",
    "    \"burst_id\",\n",
    "    \"burst_type\",\n",
    "    \"burst_type_Nonproduction\",\n",
    "    \"burst_type_Input\",\n",
    "    \"burst_type_Remove/Cut\",\n",
    "    \"is_new_burst_start\",\n",
    "    \"is_new_burst_start_Nonproduction\",\n",
    "    \"is_new_burst_start_Input\",\n",
    "    \"is_new_burst_start_Remove/Cut\",\n",
    "    \"burst_time_start\",\n",
    "    \"burst_time_end\",\n",
    "    \"burst_duration\",\n",
    "\n",
    "    \"down_time\",\n",
    "    \"up_time\",\t\n",
    "    \"action_time\",\t\n",
    "    \"activity\",\t\n",
    "    \"activity_Nonproduction\",\n",
    "    \"activity_Input\",\n",
    "    \"activity_Remove/Cut\",\n",
    "    \"down_event\",\t\n",
    "    \"up_event\",\t\n",
    "    \"text_change\",\n",
    "    \"cursor_position\",\t\n",
    "    \"word_count\",\n",
    "\n",
    "    \"up_time_lag1\",\n",
    "    \"preceding_pause_time\",\n",
    "    \"preceding_pause_time_bucket\",\n",
    "\n",
    "    \"burst_action_time_Nonproduction\",\n",
    "    \"burst_action_time_Input\",\n",
    "    \"burst_action_time_Remove/Cut\"\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_sum_wrt_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    [\n",
    "        ['activity_' + x for x in ACTIVITY_CATEGORIES] \n",
    "        + ['is_new_burst_start'] \n",
    "        + ['is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    ]\n",
    "    .agg(sum)\n",
    "    )\n",
    "X_train_marginals_sum_wrt_time['delete_insert_ratio'] = (\n",
    "    X_train_marginals_sum_wrt_time['activity_Remove/Cut'] / \n",
    "    X_train_marginals_sum_wrt_time['activity_Input'] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_central_tendency_wrt_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        pause_time_p50 = ('preceding_pause_time', np.median),\n",
    "        burst_duration_mean = ('burst_duration', 'mean'),\n",
    "        burst_duration_p50 = ('burst_duration', np.median)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_extremes_wrt_time = (\n",
    "    X_train\n",
    "    .groupby('id')\n",
    "    .agg(\n",
    "        pause_time_max=('preceding_pause_time', 'max'),\n",
    "        # approximation to, next longest pause after first long planning pause\n",
    "        pause_time_p99=('preceding_pause_time', lambda x: x.quantile(0.99)),\n",
    "        burst_duration_max=('burst_duration', 'max'),\n",
    "        total_time=('up_time', 'max')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm\n",
    "\n",
    "pause_distr_summary_subjects = []\n",
    "\n",
    "for X_train_subject in [x for _, x in X_train.groupby('id')]:\n",
    "\n",
    "    shape, location, scale = lognorm.fit(X_train_subject['preceding_pause_time'].dropna())\n",
    "\n",
    "    pause_distr_summary = pd.DataFrame({\n",
    "        'pauses_lognorm_shape': [shape], \n",
    "        'pauses_lognorm_location': [location],\n",
    "        'pauses_lognorm_scale': [scale]\n",
    "        })\n",
    "    pause_distr_summary.index = [X_train_subject['id'].iloc[0]]\n",
    "    \n",
    "    pause_distr_summary_subjects.append(pause_distr_summary)\n",
    "\n",
    "X_train_marginals_distr_params_wrt_time = pd.concat(pause_distr_summary_subjects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_wrt_time = pd.merge(\n",
    "    X_train_marginals_sum_wrt_time, \n",
    "    X_train_marginals_central_tendency_wrt_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "X_train_marginals_wrt_time = pd.merge(\n",
    "    X_train_marginals_wrt_time, \n",
    "    X_train_marginals_extremes_wrt_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "X_train_marginals_wrt_time = pd.merge(\n",
    "    X_train_marginals_wrt_time, \n",
    "    X_train_marginals_distr_params_wrt_time,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "X_train_marginals_wrt_time = (\n",
    "    X_train_marginals_wrt_time\n",
    "    .assign(writing_speed = lambda x: (x.activity_Input + x['activity_Remove/Cut']) / x.total_time)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_wrt_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_marginals_wrt_time.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_by_window = (\n",
    "    X_train\n",
    "    .groupby(['id', 'window_30s'])\n",
    "    [\n",
    "        ['activity_' + x for x in ACTIVITY_CATEGORIES] \n",
    "        + ['is_new_burst_start'] \n",
    "        + ['is_new_burst_start_' + x for x in ACTIVITY_CATEGORIES]\n",
    "    ]\n",
    "    .agg(sum)\n",
    "    .astype(float)\n",
    "    .reset_index(drop=False)\n",
    "    )\n",
    "\n",
    "X_train_by_window['delete_insert_ratio'] = (\n",
    "    X_train_by_window['activity_Remove/Cut'] / \n",
    "    X_train_by_window['activity_Input'] \n",
    "    )\n",
    "\n",
    "X_train_by_window['window_30s_idx'] = X_train_by_window.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_windows_variation = (\n",
    "    X_train_by_window\n",
    "    .drop(columns=['window_30s', 'window_30s_idx'])\n",
    "    .groupby(['id'])\n",
    "    .agg(np.std)\n",
    "    )\n",
    "\n",
    "X_train_windows_variation.columns = [\n",
    "    x + \"_stddev\"\n",
    "    for x in X_train_windows_variation.columns\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_windows_variation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = pd.merge(\n",
    "    X_train_marginals_wrt_time,\n",
    "    X_train_windows_variation,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_transform\n",
    "    .drop(columns='delete_insert_ratio_stddev')\n",
    "    .to_pickle(\"./data/processed/X_train.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
