{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:18:00.248937: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:18:00.279313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 19:18:00.279334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 19:18:00.280254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 19:18:00.285025: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:18:00.285338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 19:18:00.920148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_LOGS = \"./data/external/train_logs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "\n",
    "    X = pd.read_csv(path)\n",
    "    X = X.sort_values([\"id\", \"event_id\"], ascending=[True, True])\n",
    "    \n",
    "    return X\n",
    "\n",
    "def scrub_activity(X):\n",
    "\n",
    "    # 'Move From' activity recorded with low-level cursor loc details\n",
    "    # extract bigger-picture 'Move From'\n",
    "    # QUESTION: what's the difference between Move From, and a cut+paste?\n",
    "    X['activity_detailed'] = X['activity']\n",
    "    X.loc[X['activity'].str.contains('Move From'), 'activity'] = 'Move'\n",
    "\n",
    "    return X\n",
    "\n",
    "def scrub_text_change(X):\n",
    "    \"\"\"\n",
    "    Problems with initial text data:\n",
    "\n",
    "    - Some hex expressions (\\\\xHH) not decoded. Instead, written literally.\n",
    "        - Examples: emdash (\\\\x96), slanted quotations & ticks.\n",
    "        \n",
    "    - Some foreign characters (accent a, overring a) not anonymized with generic q.\n",
    "    Problem confirmed via Kaggle data viewer, for id-event_id cases like \n",
    "    0916cdad-39 or 9f328eb3-19. Solutions:\n",
    "        - An Input event cannot include multiple characters: \n",
    "        foreign character & something else. \n",
    "        Then, \n",
    "            - If Input event contains any emdash, overwrite as strictly emdash\n",
    "            - If Input event contains no emdash & foreign character, overwrite with single q\n",
    "            - If Move event, replace any foreign character with single q\n",
    "    \"\"\"\n",
    "\n",
    "    X['text_change_original'] = X['text_change']\n",
    "\n",
    "    # expect this transforms all \\xHH literals\n",
    "    X['text_change'] = (\n",
    "        X\n",
    "        ['text_change_original']\n",
    "        # arrived at utf-8 encode, windows-1252 decode after several iterations.\n",
    "        # tested latin-1, but not all \\xHH instances caught.\n",
    "        # tested utf-16, just rose errors.\n",
    "        .apply(lambda x: x.encode(encoding='utf-8').decode(\"windows-1252\"))\n",
    "    )\n",
    "\n",
    "\n",
    "    is_text_change_decode_english = (\n",
    "        X['text_change'].apply(lambda x: x.isascii())\n",
    "    )\n",
    "\n",
    "    is_input_event_foreign_any_emdash = (\n",
    "        (~ is_text_change_decode_english)\n",
    "        & (X['activity'] == \"Input\") \n",
    "        & (X['text_change'].str.contains(\"窶能"))\n",
    "    )\n",
    "    X.loc[is_input_event_foreign_any_emdash, 'text_change'] = \"窶能"\n",
    "\n",
    "    is_input_event_foreign_no_overwrite = (\n",
    "        (~ is_text_change_decode_english)\n",
    "        & (X['activity'] == \"Input\")\n",
    "        & (~ X['text_change'].str.contains(\"窶能"))\n",
    "    )\n",
    "    X.loc[is_input_event_foreign_no_overwrite, 'text_change'] = 'q'\n",
    "\n",
    "\n",
    "    # given block text change, proceed one character at a time,\n",
    "    # replacing foreign ones \n",
    "    def anonymize_non_ascii(x):\n",
    "        value = \"\"\n",
    "        for x_i in x:\n",
    "            if not x_i.isascii():\n",
    "                value += \"q\"\n",
    "            else:\n",
    "                value += x_i\n",
    "        return value\n",
    "\n",
    "    X['text_change'] = np.where(\n",
    "        X['activity'].str.contains('Move|Remove|Paste|Replace', regex=True),\n",
    "        X['text_change'].apply(lambda x: anonymize_non_ascii(x)),\n",
    "        X['text_change']\n",
    "    )\n",
    "\n",
    "    return X\n",
    "\n",
    "def concatenate_essay_from_logs(df):\n",
    "    \"\"\"\n",
    "    Concatenate essay text from disparate logged input events.\n",
    "    Expect df to be *one* author's log.\n",
    "    Adapted from sources: \n",
    "        https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features,\n",
    "        https://www.kaggle.com/code/kawaiicoderuwu/essay-contructor.\n",
    "    \"\"\"\n",
    "\n",
    "    input_events = df.loc[\n",
    "        (df.activity != 'Nonproduction'), \n",
    "        ['activity_detailed', 'cursor_position', 'text_change']\n",
    "        ].rename(columns={'activity_detailed': 'activity'})\n",
    "\n",
    "    essay_text = \"\"\n",
    "    for input_event in input_events.values:\n",
    "\n",
    "        activity = input_event[0]\n",
    "        cursor_position_after_event = input_event[1]\n",
    "        text_change_log = input_event[2]\n",
    "\n",
    "        if activity == 'Replace':\n",
    "\n",
    "            replace_from_to = text_change_log.split(' => ')\n",
    "            text_add = replace_from_to[1]\n",
    "            text_remove = replace_from_to[0]\n",
    "            cursor_position_start_text_change = (\n",
    "                cursor_position_after_event - len(text_add)\n",
    "                )\n",
    "            cursor_position_after_skip_replace = (\n",
    "                cursor_position_start_text_change + len(text_remove)\n",
    "            )\n",
    "\n",
    "            # essayText start: \"the blue cat\"\n",
    "            # replace \"blue\" with \"red\"\n",
    "            # \"the redblue cat\", skip blue\n",
    "            essay_text = (\n",
    "                essay_text[:cursor_position_start_text_change] # \"the \"\n",
    "                + text_add # \"red\"\n",
    "                # essayText value: \"the blue cat\" \n",
    "                # want remaining \" cat\", NOT \"blue cat\"\n",
    "                + essay_text[cursor_position_after_skip_replace:] \n",
    "                )\n",
    "\n",
    "            continue\n",
    "\n",
    "        if activity == 'Paste':\n",
    "\n",
    "            cursor_position_start_text_change = (\n",
    "                cursor_position_after_event - len(text_change_log)\n",
    "                )\n",
    "\n",
    "            # essayText start: \"the cat\"\n",
    "            # paste \"blue \" between\n",
    "            essay_text = (\n",
    "                essay_text[:cursor_position_start_text_change] # \"the \" \n",
    "                + text_change_log # \"blue \"\n",
    "                # essayText value: \"the cat\"\n",
    "                + essay_text[cursor_position_start_text_change:]\n",
    "            )\n",
    "\n",
    "            continue\n",
    "\n",
    "        if activity == 'Remove/Cut':\n",
    "            # similar process to \"Replace\" action\n",
    "\n",
    "            text_remove = text_change_log\n",
    "            cursor_position_after_skip_remove = (\n",
    "                cursor_position_after_event + len(text_remove)\n",
    "            )\n",
    "\n",
    "            essay_text = (\n",
    "                essay_text[:cursor_position_after_event] \n",
    "                + essay_text[cursor_position_after_skip_remove:]\n",
    "                )\n",
    "\n",
    "            continue\n",
    "        \n",
    "        if \"Move\" in activity:\n",
    "\n",
    "            cursor_intervals_raw_str = (\n",
    "                activity[10:]\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                )\n",
    "            cursor_intervals_separate = cursor_intervals_raw_str.split(' To ')\n",
    "            cursor_intervals_vectors = [\n",
    "                x.split(', ') \n",
    "                for x in cursor_intervals_separate\n",
    "                ]\n",
    "            cursor_interval_from = [\n",
    "                int(x) for x in cursor_intervals_vectors[0]\n",
    "                ]\n",
    "            cursor_interval_to = [\n",
    "                int(x) for x in cursor_intervals_vectors[1]\n",
    "                ]\n",
    "\n",
    "            # \"the blue cat ran\", move \"blue\" to\n",
    "            # \"the cat blue ran\"\n",
    "            # note: no change in total text length\n",
    "\n",
    "            if cursor_interval_from[0] != cursor_interval_to[0]:\n",
    "\n",
    "                if cursor_interval_from[0] < cursor_interval_to[0]:\n",
    "                    \n",
    "                    essay_text = (\n",
    "                        # all text preceding move-impacted window\n",
    "                        essay_text[:cursor_interval_from[0]] +\n",
    "                        # skip where moved block _was_,\n",
    "                        # proceed to end of move-impacted window\n",
    "                        essay_text[cursor_interval_from[1]:cursor_interval_to[1]] +\n",
    "                        # add moved block\n",
    "                        essay_text[cursor_interval_from[0]:cursor_interval_from[1]] + \n",
    "                        # all text proceeding move-impacted window\n",
    "                        essay_text[cursor_interval_to[1]:]\n",
    "                    )\n",
    "\n",
    "                # \"the cat ran fast\", move \"ran\" to \n",
    "                # \"ran the cat fast\"\n",
    "                else:\n",
    "\n",
    "                    essay_text = (\n",
    "                        # all text preceding move-impacted window\n",
    "                        essay_text[:cursor_interval_to[0]] + \n",
    "                        # add moved block\n",
    "                        essay_text[cursor_interval_from[0]:cursor_interval_from[1]] +\n",
    "                        # skip moved block, still within move-impacted window\n",
    "                        essay_text[cursor_interval_to[0]:cursor_interval_from[0]] + \n",
    "                        # all text proceeding move-impacted window\n",
    "                        essay_text[cursor_interval_from[1]:]\n",
    "                    )\n",
    "      \n",
    "            continue\n",
    "        \n",
    "\n",
    "        cursor_position_start_text_change = (\n",
    "            cursor_position_after_event - len(text_change_log)\n",
    "            )\n",
    "        essay_text = (\n",
    "            essay_text[:cursor_position_start_text_change] \n",
    "            + text_change_log\n",
    "            + essay_text[cursor_position_start_text_change:]\n",
    "            )\n",
    "        \n",
    "    return pd.DataFrame({'id': df['id'].unique(), 'essay': [essay_text]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logs = extract(PATH_TRAIN_LOGS)\n",
    "X_train_logs = scrub_activity(X_train_logs)\n",
    "X_train_logs = scrub_text_change(X_train_logs)\n",
    "\n",
    "X_train_logs = [x for _, x in X_train_logs.groupby('id')]\n",
    "essays_text = pd.concat(\n",
    "    [concatenate_essay_from_logs(x) for x in X_train_logs],\n",
    "    axis=0\n",
    ")\n",
    "# keras TextVectorization does not recognize emdash as punctuation\n",
    "essays_text['essay'] = essays_text['essay'].str.replace(\"窶能", \" \") \n",
    "\n",
    "y = pd.read_csv(\"./data/external/train_scores.csv\")\n",
    "y.rename(columns={'score': 'y'}, inplace=True)\n",
    "XY = pd.merge(essays_text, y, how='left')\n",
    "X, y = XY['essay'].to_numpy(), XY['y'].to_numpy()\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.33, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# in tf Dataset structure, one element is one X-y pair \n",
    "XY_train = tf.data.Dataset.from_tensor_slices((X, y)).batch(BATCH_SIZE)\n",
    "X_train = XY_train.map(lambda x, y: x)\n",
    "\n",
    "XY_test = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)\n",
    "X_test = XY_test.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    # with anonymized text, downscale recommended vocabulary size by magnitude \n",
    "    max_tokens=20000,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=2,\n",
    "    output_mode='tf_idf'\n",
    "    )\n",
    "\n",
    "text_vectorization.adapt(X_train)\n",
    "# values = text_vectorization.get_vocabulary()\n",
    "\n",
    "tfidf_XY_train = XY_train.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4\n",
    ")\n",
    "\n",
    "tfidf_XY_test = XY_test.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = text_vectorization.vocabulary_size()\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(n_tokens,))\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Dense(16, activation='relu'),\n",
    "#     keras.layers.Dense(1)\n",
    "#     ])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 9.1793 - val_loss: 1.8272\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 3.0883 - val_loss: 1.3944\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.7899 - val_loss: 1.7751\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.5555 - val_loss: 1.6346\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4733 - val_loss: 1.1977\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.3135 - val_loss: 1.5495\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.1167 - val_loss: 1.4345\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 1.5349\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.1011 - val_loss: 1.0981\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9153 - val_loss: 1.0534\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7682 - val_loss: 1.2551\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7340 - val_loss: 0.9692\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8211 - val_loss: 1.0387\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6645 - val_loss: 1.1119\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6436 - val_loss: 1.1618\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6019 - val_loss: 1.2552\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6236 - val_loss: 1.0042\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5498 - val_loss: 0.9412\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4340 - val_loss: 0.9635\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3557 - val_loss: 0.8440\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3728 - val_loss: 1.1707\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3229 - val_loss: 0.9888\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3219 - val_loss: 0.7952\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2491 - val_loss: 0.8485\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2411 - val_loss: 0.8033\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2132 - val_loss: 1.0574\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2577 - val_loss: 0.7552\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1674 - val_loss: 1.3408\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1456 - val_loss: 0.7761\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 0.8343\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0072 - val_loss: 0.7333\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0488 - val_loss: 0.8105\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0328 - val_loss: 0.6930\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9640 - val_loss: 0.6961\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0134 - val_loss: 0.7860\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0084 - val_loss: 0.8921\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9442 - val_loss: 0.6670\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9377 - val_loss: 0.6671\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9437 - val_loss: 0.6545\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9056 - val_loss: 0.6522\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8878 - val_loss: 0.7771\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8334 - val_loss: 0.6675\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7937 - val_loss: 0.7389\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8416 - val_loss: 0.6555\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8650 - val_loss: 0.6142\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8173 - val_loss: 0.6137\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8307 - val_loss: 0.7100\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7810 - val_loss: 0.8216\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8009 - val_loss: 0.7550\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7536 - val_loss: 0.5976\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7292 - val_loss: 0.6997\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7524 - val_loss: 0.6130\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6854 - val_loss: 0.6562\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7356 - val_loss: 0.6598\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6913 - val_loss: 0.6203\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7163 - val_loss: 0.6610\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7049 - val_loss: 0.6006\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6966 - val_loss: 0.6018\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7095 - val_loss: 0.6141\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7317 - val_loss: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1f5b8e3ca0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(\n",
    "    tfidf_XY_train.cache(),\n",
    "    validation_data=tfidf_XY_test.cache(),\n",
    "    epochs=100,\n",
    "    callbacks=[callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram=4:\n",
    "    # with punctuation: validation mse min is 0.6\n",
    "    # same without punctuation\n",
    "\n",
    "# ngram=2\n",
    "    # losing punctuation: again, mse ~0.6\n",
    "    # with punctuation: mse worsens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
