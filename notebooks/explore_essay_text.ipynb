{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import lognorm, skew, kurtosis, entropy\n",
    "\n",
    "from src.data.extract_scrub_essay_text import extract, scrub_activity, scrub_text_change, concatenate_essay_from_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_LOGS = \"./data/external/train_logs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract(PATH_TRAIN_LOGS)\n",
    "X = scrub_activity(X)\n",
    "X = scrub_text_change(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_text = pd.concat(\n",
    "    [concatenate_essay_from_logs(x) for _, x in X.groupby('id')], axis=0\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "# two consecutive newlines constitute one effective\n",
    "# no paragraph breaks imply, all 1 paragraph\n",
    "essays_text['n_paragraphs'] = essays_text['essay'].str.count(\"[\\n]+\")\n",
    "essays_text.loc[essays_text['n_paragraphs'] == 0, 'n_paragraphs'] = 1\n",
    "essays_text['paragraphs'] = essays_text['essay'].str.split(\"[\\n]+\")\n",
    "essays_text['n_sentences_by_paragraph'] = (\n",
    "    essays_text['paragraphs']\n",
    "    .apply(lambda paragraphs: [len(re.findall(\"[\\.]+|[?]+|[!]+\", p)) for p in paragraphs])\n",
    "    )\n",
    "# for bounds guidance, see overall distribution\n",
    "varnames_n_paragraphs_by_n_sentences_bin = []\n",
    "for geq_low, lt_high in [\n",
    "    (0, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 6),\n",
    "    (6, 7),\n",
    "    (7, 10),\n",
    "    (10, 20),\n",
    "    (20, 50)\n",
    "    ]:\n",
    "\n",
    "    bin_var = f'n_paragraphs_with_n_sentences_geq{geq_low}_lt{lt_high}'\n",
    "    varnames_n_paragraphs_by_n_sentences_bin += [bin_var, bin_var + \"_frac\"]\n",
    "\n",
    "    essays_text[bin_var] = (\n",
    "        essays_text['n_sentences_by_paragraph']\n",
    "        .apply(lambda x: ( (x >= geq_low) & (x < lt_high) ).sum() )\n",
    "        )\n",
    "    \n",
    "    essays_text[bin_var + \"_frac\"] = (\n",
    "        essays_text[bin_var] / essays_text['n_paragraphs']\n",
    "        )\n",
    "\n",
    "\n",
    "# sentences split can leave last hanging ' ', if not scrubbed by search for 'q'\n",
    "essays_text['sentences'] = essays_text['essay'].str.split(\"[\\.]+|[?]+|[!]+\")\n",
    "essays_text['sentences'] = (\n",
    "    essays_text['sentences']\n",
    "    .apply(lambda sentences: [s for s in sentences if 'q' in s])\n",
    ")\n",
    "essays_text['n_sentences'] = (\n",
    "    essays_text['sentences']\n",
    "    .apply(lambda s_split: len(s_split))\n",
    ")\n",
    "\n",
    "essays_text['words_by_sentence'] = (\n",
    "    essays_text['sentences']\n",
    "    .apply(lambda sentences: [s.split() for s in sentences])\n",
    ")\n",
    "essays_text['i_words_by_sentence'] = (\n",
    "    essays_text['words_by_sentence']\n",
    "    .apply(lambda sentences: np.array([len(s) for s in sentences]))\n",
    ")\n",
    "\n",
    "# for bounds guidance, see overall distribution\n",
    "varnames_n_sentences_by_word_count_bin = []\n",
    "for geq_low, lt_high in [\n",
    "    (0, 5),\n",
    "    (5, 10),\n",
    "    (10, 15),\n",
    "    (15, 20),\n",
    "    (20, 25),\n",
    "    (25, 30),\n",
    "    (30, 50),\n",
    "    (50, 5000)\n",
    "    ]:\n",
    "\n",
    "    bin_var = f'n_sentences_words_geq{geq_low}_lt{lt_high}'\n",
    "    varnames_n_sentences_by_word_count_bin += [bin_var, bin_var + \"_frac\"]\n",
    "\n",
    "    essays_text[bin_var] = (\n",
    "        essays_text['i_words_by_sentence']\n",
    "        .apply(lambda x: ( (x >= geq_low) & (x < lt_high) ).sum() )\n",
    "        )\n",
    "    \n",
    "    essays_text[bin_var + \"_frac\"] = (\n",
    "        essays_text[bin_var] / essays_text['n_sentences']\n",
    "        )\n",
    "\n",
    "\n",
    "essays_text['words'] = essays_text['essay'].str.split(\" +\", regex=True)\n",
    "essays_text[\"word_count_reconstructed\"] = (\n",
    "    essays_text\n",
    "    [\"words\"]\n",
    "    .apply(lambda x: len(x))\n",
    ")\n",
    "essays_text[\"words_length\"] = (\n",
    "    essays_text[\"words\"]\n",
    "    .apply(lambda x: np.array([len(a) for a in x]))\n",
    ")\n",
    "\n",
    "# for bounds guidance, see distribution of word lengths\n",
    "varnames_i_words_by_length_bin = []\n",
    "for geq_low, lt_high in [\n",
    "    (0, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 6),\n",
    "    (6, 7),\n",
    "    (7, 8),\n",
    "    # \"incomprehensible\" is a reasonable, long (21-char) word\n",
    "    (8, 25),\n",
    "    (25, 500)\n",
    "]:\n",
    "    bin_var = f'words_length_geq{geq_low}_lt{lt_high}'\n",
    "    varnames_i_words_by_length_bin += [bin_var, bin_var + \"_frac\"]\n",
    "\n",
    "    essays_text[bin_var] = (\n",
    "        essays_text['words_length']\n",
    "        .apply(lambda x: ( (x >= geq_low) & (x < lt_high) ).sum() )\n",
    "        )\n",
    "    essays_text[bin_var + \"_frac\"] = (\n",
    "        essays_text[bin_var] / essays_text['word_count_reconstructed']\n",
    "        )\n",
    "\n",
    "\n",
    "essays_text['n_thought_delimiting_punctuation'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"[\\.]+|[?]+|[!]+|[,]+|[-]+|[;]+|[:]+|[â€”]+\")\n",
    "    )\n",
    "essays_text[\"words_per_thought_delimiting_punctuation_avg\"] = (\n",
    "    essays_text[\"word_count_reconstructed\"] / \n",
    "    essays_text['n_thought_delimiting_punctuation']\n",
    ")\n",
    "\n",
    "essays_text['n_parenthetical_punctuation'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"\\(|\\)|\\[|\\]|\\*|{|}\")\n",
    ")\n",
    "\n",
    "essays_text['n_quant_punctuation'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"=|>|<|\\$|\\%|\\+\")\n",
    ")\n",
    "\n",
    "essays_text['n_apostrophe'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"'\")\n",
    ")\n",
    "\n",
    "essays_text['n_quotes'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"\\\"\")\n",
    ")\n",
    "\n",
    "essays_text['n_shortening_punctuation'] = (\n",
    "    essays_text\n",
    "    ['essay']\n",
    "    .str\n",
    "    .count(\"&|@\")\n",
    ")\n",
    "\n",
    "for var in ['i_words_by_sentence', 'words_length']:\n",
    "    essays_text[f\"{var}_stddev\"] = essays_text[var].apply(lambda x: x.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_text['n_sentences_by_paragraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958229,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_length = np.concatenate(\n",
    "    [essays_text['words_length'][i] for i in range(essays_text.shape[0])]\n",
    ")\n",
    "words_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      0.0\n",
       "0.1      2.0\n",
       "0.2      2.0\n",
       "0.3      3.0\n",
       "0.4      4.0\n",
       "0.5      4.0\n",
       "0.6      5.0\n",
       "0.7      6.0\n",
       "0.8      7.0\n",
       "0.9      9.0\n",
       "1.0    373.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(words_length).quantile([x/10 for x in range(10+1)])\n",
    "# pd.Series(words_length).quantile([0.9, 0.95, 0.98, 0.99])\n",
    "# <= 2\n",
    "# 3\n",
    "# 4\n",
    "# 5\n",
    "# 6\n",
    "# 7\n",
    "# >= 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52743,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_by_sentence = np.concatenate(\n",
    "    [essays_text['n_words_by_sentence'][i] for i in range(essays_text.shape[0])]\n",
    ")\n",
    "n_words_by_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      1.0\n",
       "0.1      7.0\n",
       "0.2     10.0\n",
       "0.3     12.0\n",
       "0.4     14.0\n",
       "0.5     16.0\n",
       "0.6     19.0\n",
       "0.7     22.0\n",
       "0.8     25.0\n",
       "0.9     31.0\n",
       "1.0    303.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(n_words_by_sentence).quantile([x/10 for x in range(10+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.471000e+03\n",
       "mean     1.000000e+00\n",
       "std      6.638074e-17\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_text[\n",
    "    [x for x in varnames_n_sentences_by_word_count_bin if '_frac' in x]\n",
    "    ].sum(axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.471000e+03\n",
       "mean     1.000000e+00\n",
       "std      7.670411e-17\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_text[\n",
    "    [x for x in varnames_n_words_by_length_bin if '_frac' in x]\n",
    "    ].sum(axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12090,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sentences_by_paragraph = np.concatenate(\n",
    "    [essays_text['n_sentences_by_paragraph'][i] for i in range(essays_text.shape[0])]\n",
    ")\n",
    "n_sentences_by_paragraph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     0.0\n",
       "0.1     1.0\n",
       "0.2     2.0\n",
       "0.3     3.0\n",
       "0.4     3.0\n",
       "0.5     4.0\n",
       "0.6     5.0\n",
       "0.7     5.0\n",
       "0.8     6.0\n",
       "0.9     8.0\n",
       "1.0    34.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(n_sentences_by_paragraph).quantile([x/10 for x in range(10+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
